\documentclass[10pt]{article}
\usepackage{geometry}                % See geometry.pdf to learn the layout options. There are lots.
\geometry{letterpaper}                   % ... or a4paper or a5paper or ... 
%\geometry{landscape}                % Activate for for rotated page geometry
\usepackage[parfill]{parskip}    % Activate to begin paragraphs with an empty line rather than an indent
\usepackage[cm]{fullpage}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage[margin=20pt, font=small, labelfont=sc, labelsep=endash]{caption}
\usepackage{subfig}
\usepackage{multirow}
%\usepackage{pstricks, pst-node,pst-tree}


\title{Analysis of loadings}
\author{Wesley Brooks}
\date{}                                           % Activate to display a given date or no date

\begin{document}
\setkeys{Gin}{width=0.9\textwidth}    %make figures a bit wider than the Sweave default.
\maketitle

<<label=read_data, echo=FALSE>>=
    #Read data into R and do some basic manipulation to get it into a usable format:
    setwd('c:/Users/wrbrooks/git/loadings/writeup')
    source('c:/Users/wrbrooks/git/loadings/code/guide.r')
    streams = c('eagle', 'joosvalley', 'otter', 'brewery', 'garfoot', 'kuenster', 'rattlesnake', 'bower')
    stream_names = list(eagle='Eagle', joosvalley='Joos', otter='Otter', bower='Bower',
                        brewery='Brewery', garfoot='Garfoot', kuenster='Kuenster', rattlesnake="Rattlesnake", aggregate="Aggregate")
    outputs = c('sstorm_tot', 'sstorm_max', 'sstorm_avg', 'stot_tot', 'stot_max', 'stot_yield', 'ptot_yield', 
                    'stot_avg', 'pstorm_tot', 'pstorm_max', 'pstorm_avg', 'ptot_tot', 'ptot_max', 'ptot_avg')
    
    #Names of the NWS data files for each creek
    nws_files = list("eagle"=c("eagle/NWS/Winona_91-94_ASCII.txt", "eagle/NWS/Winona_03-07_ASCII.txt"),
                        "joosvalley"=c("eagle/NWS/Winona_91-94_ASCII.txt", "eagle/NWS/Winona_03-07_ASCII.txt"),
                        "otter"=c("otter/NWS/Sheboygan_Otter_raw.txt"),
                        "brewery"=c("brewery/NWS/Madison_SND.txt"),
                        "garfoot"=c("garfoot/NWS data/madison_daily.txt"),
                        "kuenster"=c("Kuenster/NWS data/Guttenberg_raw.txt"),
                        "rattlesnake"=c("Kuenster/NWS data/Guttenberg_raw.txt"),
                        "bower"=c("bower/NWS data/greenbay_raw.txt", "bower/NWS data/greenbaypost_raw.txt"))
    
    #Location of the raw loading data file for each creek
    daily_load_data = list()
    raw_load_files = list("eagle"=c("eagle/eagle_loads.txt"),
                        "joosvalley"=c("joosvalley/joos_loads.txt"),
                        "otter"=c("otter/otter_loads.txt"),
                        "brewery"=c("brewery/brewery_loads.txt"),
                        "garfoot"=c("garfoot/garfoot_loads.txt"),
                        "kuenster"=c("Kuenster/kuenster_loads.txt"),
                        "rattlesnake"=c("Rattlesnake/rattle_loads.txt"),
                        "bower"=c("bower/bower_loads.txt"))
    
    watersheds = read.csv("../data/watersheds.csv", header=T)
    
    #A list to hold the ecdf functions for antecedent base flow.
    flow_cdf = list()
    
    #loop through the streams, reading them in one by one
    for(stream_name in streams)
    {
        data_file = paste('../data/', stream_name, '/', stream_name, 'creek.csv', sep='')
        stream = read.csv(data_file, header=T, na.strings=c('NA', 'na')) 
        
        #read the daily flow file, which we use for antecedent moisture contitions
        daily_flow = paste("../data/", stream_name, "/", stream_name, "_q.out", sep="")
        head = strsplit( readLines(daily_flow)[1], "\t" )
        daily_flow = read.table(daily_flow, skip=2, col.names=unlist(head))
        daily_flow$DV_date = with( daily_flow, as.POSIXlt( as.character(DV_date), format="%m/%d/%Y" ) )
        
        #do some basic data transformations:
        stream = within( stream, {
            event_type <- factor(event_type)
            stot_yield <- stot_tot / watersheds$area[watersheds$stream==stream_name]
            ptot_yield <- ptot_tot / watersheds$area[watersheds$stream==stream_name]
            year <- factor(year)
            melt_snow[melt_snow=='N' | melt_snow=='Z' | melt_snow=='U'] <- NA
            melt_snow <- as.numeric(levels(melt_snow)[melt_snow])
            sweq <- as.numeric(sub("%", "e-2", sweq))
            ap_1day <- as.numeric(ap_1day)
            ap_3day <- as.numeric(ap_3day)
            ap_5day <- as.numeric(ap_5day) 
            tmax <- as.numeric(tmax)
            tmin <- as.numeric(tmin)
            tmean <- as.numeric(tmean)
            stream <- as.factor(stream_name)
            start_day <- as.POSIXlt( as.character(start_day), format="%m/%d/%Y" )
            year <- as.numeric(as.character(year))
            water_year <- ifelse(month>=10, year+1, year)
            julian <- start_day$yday + 1
            sin_julian <- sin(julian*2*pi/365 - 0.35)
            cos_julian <- cos(julian*2*pi/365 - 0.35)
            for(output in outputs)
                assign( paste('log_', output, sep=""), log10(get(output)+0.01) )
            m <- as.factor(ifelse(is.na(m),0,ifelse(m=='M','M',0)))
            event <- rep(1, length(m))
            area <- watersheds$area[watersheds$stream==stream_name]
            slope <- watersheds$slope[watersheds$stream==stream_name]
            urb <- watersheds$urb[watersheds$stream==stream_name]
            logit_urb = log((urb/100)/(1-(urb/100)))
            ag <- watersheds$ag[watersheds$stream==stream_name]
            logit_ag = log((ag/100)/(1-(ag/100)))
            forest <- watersheds$forest[watersheds$stream==stream_name]
            logit_forest = log((forest/100)/(1-(forest/100)))
            water <- watersheds$water[watersheds$stream==stream_name]
            wetland <- watersheds$wetland[watersheds$stream==stream_name]
            other <- watersheds$other[watersheds$stream==stream_name]
            } )
    
        #Get the raw daily loads at each site
        daily_load = data.frame()
        for( raw_load_file in get(stream_name, pos=raw_load_files)) {
            raw_path = paste("../data/", raw_load_file, sep="")
            daily_load = rbind(daily_load, read.table(raw_path, na.strings=c("", "99999", "-1.23E+25"), header=TRUE)) }
        daily_load$date = with( daily_load, as.POSIXlt( as.character(date), format="%m/%d/%Y" ) )
        daily_load_data[[stream_name]] = daily_load
        
        #Find the base flow that immediately preceded each event
        antecedent_qbase = rep(NA, length(stream$start_day))
        for( i in 1:length(antecedent_qbase) ) {
            #get the date just prior to row i (subtraction is in units of seconds)
            unmatched = identical(which( daily_flow$DV_date == stream$start_day[i]-86400 ), integer(0))
            antecedent_qbase[i] = ifelse(unmatched, NA, daily_flow[which( daily_flow$DV_date == stream$start_day[i]-86400 ), 'QGW_fixed']) }
        stream$antecedent_qbase = antecedent_qbase
    
        flow_cdf[[stream_name]] = ecdf(antecedent_qbase)
        stream$antecedent_qbase_quantile = flow_cdf[[stream_name]](antecedent_qbase)
        stream$antecedent_qbase2 = antecedent_qbase / watersheds$area[watersheds$stream==stream_name]
        
        #Find the average air temperature in the days before the event:
        #first, read the raw air temperature data
        nws = data.frame()
        for( nws_file in get(stream_name, pos=nws_files))
        {
            nws_path = paste("../data/", nws_file, sep="")
            nws = rbind(nws, read.csv(nws_path, na.strings=c("", "99999", "-1.23E+25", "null"), header=TRUE))
        }
        nws$date = with(nws, ISOdate(year=year, month=month, day=day))
    
        #Now find the antecedent air temperature for each event
        #We will compute the mean, min, and range of air temps before this event began.
        antecedent_tmean = rep(NA, length(stream$start_day))
        antecedent_trange = rep(NA, length(stream$start_day))
        antecedent_tmax = rep(NA, length(stream$start_day))
        period = 2 #how far back in days to do the averaging
        for( i in 1:length(antecedent_tmean) )
        {
            to_average = which(nws$date < stream$start_day[i] & nws$date >= stream$start_day[i] - period*86400)
            antecedent_tmean[i] = mean(nws$Tmean[to_average], na.rm=TRUE)
            antecedent_tmax[i] = max(nws$Tmean[to_average], na.rm=TRUE) 
            antecedent_trange[i] = diff(range(nws$Tmean[to_average], na.rm=TRUE))
        }
        stream$antecedent_tmean = antecedent_tmean
        stream$antecedent_tmax = ifelse(antecedent_tmax>-Inf, antecedent_tmax, NA)
        stream$antecedent_trange = ifelse(antecedent_trange>-Inf, antecedent_trange, NA)
    
        #Now add this stream's data to the frame.
        assign(stream_name, stream)
        assign(paste(stream_name, "_flow", sep=""), daily_flow)
    }
    
    #Now mark the class of each event (1:snowmelt-driven, 2:pre-vegetation, 3:post-vegetation)
    #We will gather all the data into one frame:
    aggregate = data.frame()
    
    #loop through the stream sites:
    for(stream_name in streams)
    {
    	stream = get(stream_name)
    
    	#Decide which events are snowmelt-driven:         
    	class = vector()
    	prev_class = 0
    	num_events = dim(stream)[1]
                    
    	#loop through the events                        
    	for(row in 1:num_events)
        {
    		#first look for the beginning of each year's snowmelt events
    		if(stream$m[row]=='M')
            {
    			class = c(class, 1)
    			prev_class = 1
            }
    		else if(prev_class==1 & (stream$month[row]>=10 | stream$julian[row]<=135))
            {
    			class = c(class, 1)
    			prev_class = 1
            }
    		else
            {
    			class = c(class, 3)
    			prev_class = 3
            }
        }
          
    	prev_class = 0
    	for(row in num_events:1)
        {
    		#now look for the end of the snowmelt events
    		if(stream$m[row]=='M')
            {
    			class[row] = 1
    			prev_class = 1
            }
    		else if(class[row]==3)
            {
    			class[row] = 3
    			prev_class = 3
            }
    		else if(stream$julian[row]<=135 & prev_class!=1)
            {
    			class[row] = 2
    			prev_class = 2
            }
    		else
                class[row] = 1
        }
    
          
    	#save the class identifiers back to the stream's data frame
    	stream$event_class = as.factor(class)
        stream$snow = ifelse(stream$event_class==1,TRUE, FALSE)
    	assign(stream_name, stream)
        aggregate = rbind(aggregate, stream)
    }
@


<<label=bubble_plots, echo=False, include=False>>=
    #The "_nosnow" dataframes exclude the snowfall-influenced events.
    num_rows = ceiling(length(streams)/2)
    layout(matrix(1:(2*num_rows), num_rows, 2))
    for(stream_name in streams)
    {
        stream = get(stream_name)
        assign( paste(stream_name, "_nosnow", sep=""), stream[stream$snow==FALSE,] )
        assign( paste(stream_name, "_snow", sep=""), stream[stream$snow==TRUE,] )
    
        #Produce the bubble plots
        symbols(stream[stream$snow==FALSE,]$antecedent_qbase_quantile,
                stream[stream$snow==FALSE,]$theisen,
                circles=sqrt( stream[stream$snow==FALSE,]$sstorm_tot/pi ),
                inches=0.25, fg="white", bg="red", bty='n',
                xlim=c(-0.05, 1.05),
                ylim=range(stream[!is.na(stream$theisen),]$theisen)*c(0.8,1.2),
                xlab="Antecedent baseflow",
                ylab="Theisen rainfall") 
        
        mtext(stream_names[[stream_name]], side=3, line=-1, cex=1.2,
              at=0.6)
    }
    
    aggregate$stream = rep("aggregate", dim(aggregate)[1])
    aggregate_nosnow = aggregate[aggregate$snow==FALSE,]
    aggregate_snow = aggregate[aggregate$snow==TRUE,]
@


<<label=function_definitions, echo=False, include=False>>=
    #Import the GAM library
    library(mgcv)
    
    #Backslash-escape special characters.
    sanitize <- function(str)
        gsub('([#$%&~_\\^\\\\{}])', '\\\\\\1', str, perl=TRUE)
    
    
    #Double-backslash-escape special characters.
    sanitize2 <- function(str)
        gsub('([#$%&~_\\^\\\\{}])', '\\\\\\\\\\1', str, perl=TRUE)
    
    
    #Paste together a list of strings, backslash-escaping special characters in each one.
    sanipaste <- function(pastelist, ...)
        paste(sanitize(pastelist), ...)
    
    
    #Paste together a list of strings, double-backslash-escaping special characers in each one.
    sanipaste2 <- function(pastelist, ...)
        paste(sanitize2(pastelist), ...)
    
    
    #Determine what proportion of loadings comes from each event class
    proportions <- function(streams, target, col.names)
    {
        result = matrix( nrow=length(streams), ncol=length(col.names) )
    	for(i in 1:length(streams))
        {
    		stream = get(streams[i])
    		result[i,] = sapply(c(TRUE, FALSE), function(x) sum(stream[stream$snow==x, target], na.rm=T) / sum(stream[,target], na.rm=T))
        }
        result = data.frame(result)
        names(result) = col.names
        row.names(result) = sapply(streams, function(x) get(x=x, pos=stream_names))
    	return(result)
    }
    
    
    #Determine what percentage of loadings comes from each event class
    percentages <- function(streams, target, col.names, decimals=1)
    {
        props = proportions(streams, target, col.names)
        result = matrix( nrow=0, ncol=length(col.names) )
        rows = dim(props)[1]
        for( row in 1:rows )
        {
            result = rbind( result, paste( ifelse(round(props[row,]*100, decimals)%%1 == 0,
                paste(as.character( round(props[row,]*100, 0) ), ".0", sep=""),
                as.character( round(props[row,]*100, decimals) )), "%", sep="" ))
        }
        result=data.frame(result)
        names(result) = names(props)
        row.names(result) = row.names(props)
        return(result)
    }
    
    
    #Extracts the terms in the model formula.
    parse_args <- function(model)
        return(attr(model$model, 'names'))
    
    
    #Compute the model's R**2.
    r2 <- function(model)
    {
        actual = model$residual+model$fitted
        rss = sum(model$residual**2)
        tss = sum((actual-mean(actual))**2)
        return(1 - rss/tss)
    }
    
    
    #Adds variables one-by-one to the model, finding the R^2 at each step.
    r2_step <- function(model, variables, data)
    {
        output = attr(model$model, "names")[1]
        call = paste(output, "~", variables[1], sep="")
        
        r_square = vector()
    
        for(variable in variables[-1]) {
            f = as.formula(call)
            model = lm(formula=f, data=data)
            r_square = c(r_square, r2(model))
            call = paste(call, "+", variable) }
        
        model = update(model, formula=call)
        r_square = c(r_square, r2(model))
        
        return(r_square)
    }
    
    
    #This function uses the BIC to screen variables, returning the 'step' object.
    stepwise_BIC <- function(target, data, sites)
    {
        predictors_raw = c("num_events", "theisen", "p5max", "p10max", "p15max", "p30max", "p60max",
                       "ei", "duration", "ap_1day", "ap_3day", "ap_5day", "tmax", "tmean", "tmin", "antecedent_qbase_quantile", 
                       "nws_prec", "nws_snow", "melt_snow", "cos_julian", "sin_julian",
                       "antecedent_tmean", "antecedent_tmax", "antecedent_trange", "slope", "area")
        d = data[,c(target, predictors_raw)]
        result = list()
        
        predictors = c(predictors_raw, "slope:theisen", "slope:antecedent_qbase_quantile", "slope:duration", "slope:area")
        full_model = as.formula( paste(target, "~", paste(predictors, collapse="+")) )
        intercept_only = as.formula( paste(target, "~1") )
        fm1 <- lm(full_model, data=d, x=T)
        
        d = data.frame(cbind(target=fm1$fitted+fm1$residual, fm1$x))
        names(d)[1] = target
        fm2 <- lm(intercept_only, data=d)
        screened = step(fm2, scope=full_model, direction='both', k=log(dim(d)[1]), trace=FALSE)
        
        terms = parse_args(screened)
        target = terms[1]
        predictors = terms[-1]
        formula = as.formula(paste(target, "~", paste(predictors, collapse="+")))
        
        model = lm(formula, data=data, x=T)
        
        #Put the results in a list object
        result$site = sites[[as.character(unique(data$stream)[1])]]
        result$model = model
        result$ranked = names(model$model)[-1] # rank_predictors(model)
        result$R2 = r2_step(model, result$ranked, data)
        return(result)
    }
    
    
    #Use the BIC to screen the predictors that are available when snow is on the ground.
    stepwise_BIC_snow <- function(target, data, sites)
    {
        predictors_raw = c("num_days", "tmax", "tmean", "tmin", "nws_prec", "nws_snow", "antecedent_qbase_quantile", 
                       "cos_julian", "sin_julian", "antecedent_tmean", "antecedent_tmax", "antecedent_trange", "slope", "area")
        d = data[,c(target, predictors_raw)]
        result = list()
    
        predictors = c(predictors_raw, "slope:nws_prec", "slope:antecedent_qbase_quantile","slope:area")
        full_model = as.formula( paste(target, "~", paste(predictors, collapse="+")) )
        intercept_only = as.formula( paste(target, "~1") )
        fm1 <- lm(full_model, data=d, x=T)
        
        d = data.frame(cbind(target=fm1$fitted+fm1$residual, fm1$x))
        names(d)[1] = target
        fm2 <- lm(intercept_only, data=d)
        screened = step(fm2, scope=full_model, direction='both', k=log(dim(d)[1]), trace=FALSE)
        
        terms = parse_args(screened)
        target = terms[1]
        predictors = terms[-1]
        formula = as.formula(paste(target, "~", paste(predictors, collapse="+")))
        
        model = lm(formula, data=data, x=T)
        
        #Put the results in a list object
        result$site = sites[[as.character(unique(data$stream)[1])]]
        result$model = model
        result$ranked = names(model$model)[-1] #rank_predictors(model)
        result$R2 = r2_step(model, result$ranked, data)
        return(result)
    }
    
    
    #Use the BIC to screen the predictors that are available when snow is on the ground.
    stepwise_BIC_snow2 <- function(target, data, sites)
    {
        predictors_raw = c("num_days", "tmax", "tmean", "tmin", "nws_prec", "nws_snow", "total_water", "melt_water", "slope", "area", "antecedent_qbase_quantile",
                       "cos_julian", "sin_julian", "antecedent_tmean", "antecedent_tmax", "antecedent_trange")
        d = data[,c(target, predictors_raw)]
        result = list()
    
        predictors = c(predictors_raw, "antecedent_qbase_quantile:slope", "antecedent_qbase_quantile:area", "total_water:slope", "total_water:area")
        full_model = as.formula( paste(target, "~", paste(predictors, collapse="+")) )
        intercept_only = as.formula( paste(target, "~1") )
        fm1 <- lm(full_model, data=d, x=T)
        
        d = data.frame(cbind(target=fm1$fitted+fm1$residual, fm1$x))
        names(d)[1] = target
        fm2 <- lm(intercept_only, data=d)
        screened = step(fm2, scope=full_model, direction='both', k=log(dim(d)[1]), trace=FALSE)
        
        terms = parse_args(screened)
        target = terms[1]
        predictors = terms[-1]
        formula = as.formula(paste(target, "~", paste(predictors, collapse="+")))
        
        model = lm(formula, data=data, x=T)
        
        #Put the results in a list object
        result$site = sites[[as.character(unique(data$stream)[1])]]
        result$model = model
        result$ranked = names(model$model)[-1] #rank_predictors(model)
        result$R2 = r2_step(model, result$ranked, data)
        return(result)
    }
    
    
    #Function to flag the largest observations of a certain variable.
    major <- function(data, target, q=0.9, strata='')
    {
        #Flag the major events within each level of strata
        if(strata != '') {
            major = rep(0, length(data[,target]))
            
            #Loop through the strata
            for(stratum in unique(data[,strata])) {
                indx = which(data[,strata]==stratum)
                major[indx] = ifelse(data[indx,target] > quantile(data[indx,target], q, na.rm=TRUE), 1, 0) } }
                
        #If no stratification is provided, then just flag the overall major events
        else { major = ifelse(data[,target]>quantile(data[,target], q, na.rm=TRUE), 1, 0) }
        
        #Either way, return the result
        return(major)
    }
    
    
    #Produce a boxplot of the per-event loading, showing rainfall- and snowmelt-driven events separately.
    bplot <- function(formula, data, loc, classes, site, ylim, ...)
    {
        boxplot(formula, data=data, bty='n', ylim=ylim, cex=0.6, pch=4,
                boxwex=0.4, frame.plot=F, ann=F, names=classes, add=T, at=loc:(loc+1), yaxt='n', ...)
        mtext(site, side=1, line=3, at=(loc+0.5))
        
        target = as.character(formula)[2]    
        target = paste(strsplit(target, "_", fixed=TRUE)[[1]][2], "_tot", sep="")
        mtext( paste(round(100*sum(data[data$snow==1,target], na.rm=TRUE)/sum(data[,target], na.rm=TRUE), 0), "%", sep=""), side=3, line=0, cex=0.7, at=loc )
        mtext( paste(round(100*sum(data[data$snow==0,target], na.rm=TRUE)/sum(data[,target], na.rm=TRUE), 0), "%", sep=""), side=3, line=0, cex=0.7, at=(loc+1) )
        
        mtext(sum(data$snow), side=3, line=1, cex=0.7, at=loc )
        mtext(length(data$snow) - sum(data$snow), side=3, line=1, cex=0.7, at=(loc+1) )
    }
    
    
    #Produce a table that shows how the R**2 grows as new variables are added to the model.
    R2_table <- function(varlist)
    {
        numvars = length(varlist$R2)
        cat(paste("\\multirow{", as.character(numvars+1), "}{*}{", varlist$site, "}", sep=""))
        for(i in 1:numvars)
        {
            cat(paste(" & ", as.character(round(varlist$R2[i], 3)), " & ", sep=""))
            
            for(j in 1:i)
            {
                cat(sanitize(varlist$ranked[j]))
                if(j<i)
                    cat(" + ")
            }
            cat("\\\\ \n")
        }
        cat("\\vspace{2mm}\\\\ \n")
    }
@



<<label=variable_selection_nosnow, echo=False, include=False>>=
    es = stepwise_BIC(target="log_stot_yield", data=eagle_nosnow, sites=stream_names)
    js = stepwise_BIC(target="log_stot_yield", data=joosvalley_nosnow, sites=stream_names)
    os = stepwise_BIC(target="log_stot_yield", data=otter_nosnow, sites=stream_names)
    bs = stepwise_BIC(target="log_stot_yield", data=brewery_nosnow, sites=stream_names)
    gs = stepwise_BIC(target="log_stot_yield", data=garfoot_nosnow, sites=stream_names)
    ks = stepwise_BIC(target="log_stot_yield", data=kuenster_nosnow, sites=stream_names)
    rs = stepwise_BIC(target="log_stot_yield", data=rattlesnake_nosnow, sites=stream_names)
    bows = stepwise_BIC(target="log_stot_yield", data=bower_nosnow, sites=stream_names)
    as = stepwise_BIC(target="log_stot_yield", data=aggregate_nosnow, sites=stream_names)
    
    ep = stepwise_BIC(target="log_ptot_yield", data=eagle_nosnow, sites=stream_names)
    jp = stepwise_BIC(target="log_ptot_yield", data=joosvalley_nosnow, sites=stream_names)
    op = stepwise_BIC(target="log_ptot_yield", data=otter_nosnow, sites=stream_names)
    bp = stepwise_BIC(target="log_ptot_yield", data=brewery_nosnow, sites=stream_names)
    gp = stepwise_BIC(target="log_ptot_yield", data=garfoot_nosnow, sites=stream_names)
    kp = stepwise_BIC(target="log_ptot_yield", data=kuenster_nosnow, sites=stream_names)
    rp = stepwise_BIC(target="log_ptot_yield", data=rattlesnake_nosnow, sites=stream_names)
    bowp = stepwise_BIC(target="log_ptot_yield", data=bower_nosnow, sites=stream_names)
    ap = stepwise_BIC(target="log_ptot_yield", data=aggregate_nosnow, sites=stream_names)
@

<<label=variable_selection_snow, include=False, echo=False>>=
    es_snow = stepwise_BIC_snow(target="log_stot_yield", data=eagle_snow, sites=stream_names)
    js_snow = stepwise_BIC_snow(target="log_stot_yield", data=joosvalley_snow, sites=stream_names)
    os_snow = stepwise_BIC_snow(target="log_stot_yield", data=otter_snow, sites=stream_names)
    bs_snow = stepwise_BIC_snow(target="log_stot_yield", data=brewery_snow, sites=stream_names)
    gs_snow = stepwise_BIC_snow(target="log_stot_yield", data=garfoot_snow, sites=stream_names)
    ks_snow = stepwise_BIC_snow(target="log_stot_yield", data=kuenster_snow, sites=stream_names)
    rs_snow = stepwise_BIC_snow(target="log_stot_yield", data=rattlesnake_snow, sites=stream_names)
    bows_snow = stepwise_BIC_snow(target="log_stot_yield", data=bower_snow, sites=stream_names)
    as_snow = stepwise_BIC_snow(target="log_stot_yield", data=aggregate_snow, sites=stream_names)
    
    ep_snow = stepwise_BIC_snow(target="log_ptot_yield", data=eagle_snow, sites=stream_names)
    jp_snow = stepwise_BIC_snow(target="log_ptot_yield", data=joosvalley_snow, sites=stream_names)
    op_snow = stepwise_BIC_snow(target="log_ptot_yield", data=otter_snow, sites=stream_names)
    bp_snow = stepwise_BIC_snow(target="log_ptot_yield", data=brewery_snow, sites=stream_names)
    gp_snow = stepwise_BIC_snow(target="log_ptot_yield", data=garfoot_snow, sites=stream_names)
    kp_snow = stepwise_BIC_snow(target="log_ptot_yield", data=kuenster_snow, sites=stream_names)
    rp_snow = stepwise_BIC_snow(target="log_ptot_yield", data=rattlesnake_snow, sites=stream_names)
    bowp_snow = stepwise_BIC_snow(target="log_ptot_yield", data=bower_snow, sites=stream_names)
    ap_snow = stepwise_BIC_snow(target="log_ptot_yield", data=aggregate_snow, sites=stream_names)
@


<<label=variable_selection_snow2, include=False, echo=False>>=
    es_snow2 = stepwise_BIC_snow2(target="log_stot_yield", data=eagle_snow, sites=stream_names)
    js_snow2 = stepwise_BIC_snow2(target="log_stot_yield", data=joosvalley_snow, sites=stream_names)
    os_snow2 = stepwise_BIC_snow2(target="log_stot_yield", data=otter_snow, sites=stream_names)
    bs_snow2 = stepwise_BIC_snow2(target="log_stot_yield", data=brewery_snow, sites=stream_names)
    gs_snow2 = stepwise_BIC_snow2(target="log_stot_yield", data=garfoot_snow, sites=stream_names)
    ks_snow2 = stepwise_BIC_snow2(target="log_stot_yield", data=kuenster_snow, sites=stream_names)
    rs_snow2 = stepwise_BIC_snow2(target="log_stot_yield", data=rattlesnake_snow, sites=stream_names)
    bows_snow2 = stepwise_BIC_snow2(target="log_stot_yield", data=bower_snow, sites=stream_names)
    as_snow2 = stepwise_BIC_snow2(target="log_stot_yield", data=aggregate_snow, sites=stream_names)
    
    ep_snow2 = stepwise_BIC_snow2(target="log_ptot_yield", data=eagle_snow, sites=stream_names)
    jp_snow2 = stepwise_BIC_snow2(target="log_ptot_yield", data=joosvalley_snow, sites=stream_names)
    op_snow2 = stepwise_BIC_snow2(target="log_ptot_yield", data=otter_snow, sites=stream_names)
    bp_snow2 = stepwise_BIC_snow2(target="log_ptot_yield", data=brewery_snow, sites=stream_names)
    gp_snow2 = stepwise_BIC_snow2(target="log_ptot_yield", data=garfoot_snow, sites=stream_names)
    kp_snow2 = stepwise_BIC_snow2(target="log_ptot_yield", data=kuenster_snow, sites=stream_names)
    rp_snow2 = stepwise_BIC_snow2(target="log_ptot_yield", data=rattlesnake_snow, sites=stream_names)
    bowp_snow2 = stepwise_BIC_snow2(target="log_ptot_yield", data=bower_snow, sites=stream_names)
    ap_snow2 = stepwise_BIC_snow2(target="log_ptot_yield", data=aggregate_snow, sites=stream_names)
@


<<label=breakdown_snow_or_rain, include=False, echo=False>>=
    for(target in c('ptot_tot', 'pstorm_tot', 'stot_tot', 'sstorm_tot'))
    {
        p = percentages(streams, target, col.names=c("snowmelt-driven", "rainfall-driven"))
        pp = as.matrix( proportions(streams, target, col.names=c("snowmelt-driven", "rainfall-driven")) )
        
        variable_name = paste(target, "_percentages", sep="")
        variable_name2 = paste(target, "_proportions", sep="")
        
        assign(variable_name, value=p)
        assign(variable_name2, value=pp)
    }
@


<<label=barchart, echo=False, include=False>>=
    layout(matrix(1:4,2,2))
    colors <- gray.colors(dim(ptot_tot_proportions)[1])
    
    barplot(ptot_tot_proportions, beside=T, names.arg=c("snow","rain"), ylab="proportion of phosphorus")
    barplot(stot_tot_proportions, beside=T, names.arg=c("snow","rain"), ylab="proportion of solids")
    barplot(pstorm_tot_proportions, beside=T, names.arg=c("snow","rain"), ylab="proportion of phosphorus")
    barplot(sstorm_tot_proportions, beside=T, names.arg=c("snow","rain"), ylab="proportion of solids")
    legend(x="topleft", legend=streams, fill=colors, bty='n')
@



\begin{figure}[h!]
    \begin{center}
<<label=fig2, fig=True, echo=False, width=6, height=8.5>>=
<<barchart>>
@
    \end{center}
    \vspace{-10mm}
    \caption{Cumulative storm loadings at the four creeks.\label{bars}}
\end{figure}


<<label=stot_boxplots, echo=False, include=False>>=
    yy = c(-2, 3.5)
    xx = c(1, 3*length(streams) + 1)
    par(mar=c(4, 4, 2, 0))
    plot.new()
    plot.window(xlim=xx, ylim=yy)
    
    for(i in 1:length(streams))
    {
        data = get(streams[i])
        site = stream_names[[streams[i]]]
        bplot(log_stot_yield~snow, data=data, loc=3*i, classes=c("snow","rain"), site=site, xlim=xx, ylim=yy)
    }
    
    mtext("count:", side=3, line=1, cex=0.7, at=0, adj=1 )
    mtext("proportion:", side=3, line=0, cex=0.7, at=0, adj=1 )
@



<<label=ptot_boxplots, echo=False, include=False>>=
    xx = c(1, 3*length(streams) + 1)
    par(mar=c(4, 4, 2, 0))
    plot.new()
    plot.window(xlim=xx, ylim=yy)
    
    for(i in 1:length(streams))
    {
        data = get(streams[i])
        site = stream_names[[streams[i]]]
        bplot(log_ptot_yield~snow, data=data, loc=3*i, classes=c("snow","rain"), site=site, xlim=xx, ylim=yy)
    }
    
    mtext("count:", side=3, line=1, cex=0.7, at=0, adj=1 )
    mtext("proportion:", side=3, line=0, cex=0.7, at=0, adj=1 )
@





%Boxplots of the contribution from individual storm events
\begin{figure}[h]
    \setkeys{Gin}{width=1\textwidth}    %make figures a bit wider than the Sweave default.
    \begin{center}
<<label=boxplot_stot, fig=True, echo=False, width=9, height=5>>=
<<stot_boxplots>>
@ \\
    \vspace{15mm}
<<label=boxplot_ptot, fig=True, echo=False, width=9, height=5>>=
<<ptot_boxplots>>
@
    \caption{Boxplots showing the sediment and phosphorus load produced by individual events at all four streams.\label{boxplots}}
    \end{center}
\end{figure}




<<label=cumulative_sloading_by_rainfall, include=False, echo=False>>=
    line_type=1
    color=1
    yy=c(0,1)
    xx = c(0,max(aggregate[aggregate$snow==FALSE,]$theisen, na.rm=T))
    
    for(stream in streams)
    {
        stream_data = get(stream)
        
        non_snow = stream_data[stream_data$snow==FALSE & !is.na(stream_data$ptot_tot),]
        non_snow_sorted = non_snow[ order(non_snow$theisen) ,]
        y = cumsum(non_snow_sorted$stot_tot)/sum(stream_data$stot_tot, na.rm=T)
        
        stream_data = get(stream)
        plot( x=non_snow_sorted$theisen, y=y, type='l', xlab="Theisen rainfall",
            ylab=paste('proportion of total sediment load'), lty=line_type, col=color, bty='n', lwd=2, ylim=yy, xlim=xx)
        par(new=T, ann=F, xaxt='n', yaxt='n')
        line_type = line_type+1
    }
    legend(x='topleft', bty='n', legend=streams, lty=1:length(streams))
@

<<label=cumulative_ploading_by_rainfall, include=False, echo=False>>=
    line_type=1
    color=1
    yy=c(0,1)
    xx = c(0,max(aggregate[aggregate$snow==FALSE,]$theisen, na.rm=T))
    
    for(stream in streams)
    {
        stream_data = get(stream)
        
        non_snow = stream_data[stream_data$snow==FALSE & !is.na(stream_data$ptot_tot) & !is.na(stream_data$theisen),]
        non_snow_sorted = non_snow[ order(non_snow$theisen) ,]
        y = cumsum(non_snow_sorted$ptot_tot)/sum(stream_data$ptot_tot, na.rm=T)
        
        stream_data = get(stream)
        plot( x=non_snow_sorted$theisen, y=y, type='l', xlab="Theisen rainfall",
            ylab=paste('proportion of total phosphorus load'), lty=line_type, col=color, bty='n', lwd=2, ylim=yy, xlim=xx)
        par(new=T, ann=F, xaxt='n', yaxt='n')
        line_type = line_type+1
    }
    legend(x='topleft', bty='n', legend=streams, lty=1:length(streams))
@


<<label=cdf_plot, include=False, echo=False>>=
    line_type=1
    color=1
    for(stream in streams)
    {
        stream_data = get(stream)
        plot( y=cumsum(sort(stream_data[,'sstorm_tot'], decreasing=T)) / sum(stream_data[,'sstorm_tot']),
              x=1:length(stream_data[,'sstorm_tot']) / length(stream_data[,'sstorm_tot']), type='l', 
              xlab='fraction of events', ylab='fraction of loading', lty=line_type, col=color, bty='n', lwd=2)
        par(new=T, ann=F, xaxt='n', yaxt='n')
        line_type = line_type+1
    }
    legend(x='bottomright', bty='n', legend=streams, lty=c(1,2,3,4))
@



<<label=proportion, include=False, echo=False>>=
    q_90 = list()
    
    for(target in c("stot_tot", "ptot_tot"))
    {
        output = paste(target, "_major", sep="")
        q=vector()
        for(stream_name in streams){
            stream = get(stream_name)
            stream[output] <- with(stream, ifelse(get(target)>quantile(get(target), 0.9, na.rm=T),1,0))
            stream$major <- with(stream, ifelse(get(target)>quantile(get(target), 0.9, na.rm=T),1,0))
            proportion = sum(stream[stream[output]==1,target], na.rm=T)/sum(stream[,target], na.rm=T)
            q = c(q, proportion)
            assign(stream_name, stream) }
            
        names(q) = streams
        q_90[[target]] = q
    }
@
    
    
<<label=by_year, include=False, echo=False, eval=False>>=
    for (year in unique(bower$water_year))
    {
        annual = bower[bower$water_year==year,]
        major_s <- with(annual, ifelse(get("stot_tot")>quantile(get("stot_tot"), 0.9, na.rm=T),1,0))
        major_p <- with(annual, ifelse(get("ptot_tot")>quantile(get("ptot_tot"), 0.9, na.rm=T),1,0))
        cat( paste(year, "\n") )
        cat( paste("number of events: ", dim(annual)[1], "\n", sep="") )
        cat( paste("sediment: total: ", sum(annual$stot_tot), ", rain: ", sum(annual$stot_tot[annual$snow==FALSE]),
                   ", snow: ", sum(annual$stot_tot[annual$snow==TRUE]), "\n") )
        cat( paste("proportion of sediment carried by year's biggest events: ", 
                   round(sum(annual$stot_tot[major_s==1], na.rm=T)/sum(annual$stot_tot, na.rm=T), 3), "\n") )
        cat( paste("proportion of sediment carried by year's biggest event: ", 
                   round(max(annual$stot_tot, na.rm=T)/sum(annual$stot_tot, na.rm=T), 3), "\n") )
        cat( paste("date of biggest sediment event: ",  annual$start_day[which.max(annual$stot_tot)], "\n") )
        cat( paste("phosphorus: total: ", sum(annual$ptot_tot), ", rain: ", sum(annual$ptot_tot[annual$snow==FALSE]), 
                   ", snow: ", sum(annual$ptot_tot[annual$snow==TRUE]), "\n") )
        cat( paste("proportion of phosphorus carried by year's biggest events: ", 
                   round(sum(annual$ptot_tot[major_p==1], na.rm=T)/sum(annual$ptot_tot, na.rm=T), 3), "\n") )
        cat( paste("proportion of phosphorus carried by year's biggest event: ", 
                   round(max(annual$ptot_tot, na.rm=T)/sum(annual$ptot_tot, na.rm=T), 3), "\n") )
        cat( paste("date of biggest phosphorus event: ",  annual$start_day[which.max(annual$ptot_tot)], "\n") )
    }
@



\section{Goal}
Stream health is threatened by high sediment and phosphorus loads, which are carried into the streams by runoff from the surrounding landscape. It has been shown previously\cite{Danz:2010} that the phosphorus and sediment loads in Wisconsin are not evenly distributed in time - rather, most of the annual loading arrives during two pulses: one in early spring, associated with the melting of the winter snowpack, and the other in midsummer, at the same time as the most intense summer thunderstorms.\\

In this study, we define loading "events" that can span multiple days of continuous runoff. Our goal is to then characterize the events that produce the greatest loading, in order to inform management practices that aim to improve stream health by reducing sediment and phosphorus loads. Our ultimate goal is a mathematical model of stream loading based on some easily-interpretable covariates. Ideally, we will arrive at a global model for all the sites in the study. The alternative are a collection of local models that seem to describe only the specific sites at which they are calibrated.\\

\section{Data}
\paragraph{Description}
The data in this report comes from eight Wisconsin streams that were monitored (with some gaps in data collection) between 1989 and 2009. The streams and the period during which each was monitored are in Table \ref{table:dates}, except that the phosphorus loading was not measured at Brewery Creek from October 1999 onward.\\

\begin{table}[h]
\begin{center}
\begin{tabular}{r c l}
        \textbf{Stream}  & \textbf{Events} & \textbf{Years}\\
        Eagle & 429 & 1991-1994, 2003-2007\\
        Joos Valley & 473 & 1990-1994, 2002-2007\\
        Otter & 424 & 1990-1997, 2000-2002\\
        Brewery & 670 & 1985, 1990-1998, 2000-2001\\
        Garfoot & 527 & 1985, 1990-1993, 1995-1998\\
        Kuenster & 218 & 1992-1995\\
        Rattlesnake & 170 & 1991-1994\\
        Bower & 373 & 1990-1994, 2006-2009\\
    \end{tabular}
    \label{table:dates}
\end{center}
\end{table}

Each entry in our data set represents one loading event. Events are defined based on the hydrograph - an event begins when the flow rises from a base level toward a peak, and ends when the flow falls back to its new base level. A computer program called Rainmaker was used to separate the total stream flow into base flow and storm flow components. The hydrograph separation is done by analyzing the beginning and ending base flows and the peak storm flow for each event. The storm flow input that drives each event can come from rainfall, from melting snow, or from some combination of the two.

Two kinds of load are measured for each event - the sediment load and the phosphorus load. The load from each event can be divided into two components: the base flow component and the storm flow component. The two components refer, respectively, to the load carried by the stream's base flow and that carried by the additional storm flow pulse. Rainmaker separates the two components based on the hydrograph.\\

Not all of the data can be collected for each event. For instance, rainfall is measured only when the ground is free of snow, because snow interferes with the rain gauges. And the amount of snowmelt is estimated by multiplying the snow's water content by the change in snow depth during a warm snap, which is inaccurate when additional snow falls during the event. Broadly, there is one set of measurements that are made during rainfall-driven events and a different set of measurements that are made during snowmelt-driven events. Because of this, the two types of event are modeled separately. Furthermore, compared to the data about events that are rainfall-driven, the data about events that are snowmelt-driven is of lower quality. That's because: the accuracy of the stream gauge is reduced by ice on the stream, the winter rainfall, snow depth, and water content are not measured locally (snow data tends (or is it always?) to come from the nearest large airport.) It would be surprising if the accuracy of models for snowmelt-driven loading were comparable to that of models for rainfall-driven loading.\\

All else being equal, a stream that drains a larger area should have a greater flow, and should carry a greater load of sediment and phosphorus. For this reason, the sediment and phosphorus loads were divided by the drainage area to get the sediment and phosphorus yields. The yields will be the output from our models.\\

We augmented the data with some antecedent values that we thought could possibly affect the loadings produced during an event. These were the base flow one day before the event, the two-day antecedent mean temperature, the maximum temperature over the two days before the event, and the range between the two-day antecedent max and min temperatures.\\

Some of the data were measured at a gauge station on each stream - these were the stream gauge, local rainfall (including intensity and duration), and the concentrations of sediment and phosphorus (the concentrations were multiplied by the stream flow to get the loadings.) Other data such as rainfall, snowfall, snow depth, snow water content, and air temperature were measured by the National Weather Service (NWS) at a permanent weather station. We downloaded these data from a database maintained by the NWS. Finally we have some metadata that describes our data at the watershed level: the drainage area, the average stream slope, and the land use composition.\\


\paragraph{Exploratory Analysis}
The first task was to determine how loads are distributed between snowmelt-driven and rainfall-driven events. The total loads from each kind of event are tabulated in Tables \ref{tab:stot} (sediment) and \ref{tab:ptot} (phosphorus). Figure \ref{bars} presents the same information as the tables, while Figure \ref{boxplots} also compares the load from indivudual snowmelt- and rainfall-driven events. In general, more of the load of both phosphorus and sediment is from rainfall-driven events, but at Garfoot and Kuenster more of the both kinds of load came from snowmelt-driven events. At all sites except Garfoot and Kuenster, snowmelt-driven events contributed a larger proportion of phosphorus loading than of sediment loading (and at Garfoot and Kuenster, difference between the proportions was small.) At most sites the difference between the proportion of sediment load produced by snowmelt-driven events and the proportion of phosphorus load produced by snowmelt-driven events was less than ten percentage points, but at Bower the difference was about 34 percentage points. This suggests that melting snow carries proportionally more phosphorus than does rainfall-runoff, which might be the case if the the phosphorus is from animal poop that accumulates on fallen snow, while the sediment comes from dirt that is mainly trapped under the snowpack.\\

\subparagraph{Rainfall-driven events}
We investigated dividing the snow-free seasons into early and late subseasons, separating the two on May 15th of each year. If vegetation serves to hold the soil together, and to increase both evapotranspiration and infiltration, then erosion may be more common early in the spring before most of the summer's vegetation appears. If so, the relationship between rainfall and the stream's loading might change during the summer.\\

The investigation was done by making linear models to describe the sediment and phosphorus loading during the two subseasons and comparing them to a single model fit to the entire snow-free period. Because the split makes the model more flexible, it will certainly improve the model's fit - the question is whether that improvement is enough to justify making the model more complex. At all four streams, the model improvement was statistically significant but too small to matter (the split models explained about 1\%-2\% more of the loads). We will not use the split in the rest of the analysis.\\

<<label=total_solids_table,echo=FALSE,results=tex>>=
    library(xtable)
    print(xtable(stot_tot_percentages, caption="Proportion of total suspended solids loading contributed by each type of event",
                 label="tab:stot", align=c('l', 'c', 'c')),
    caption.placement="bottom", hline.after=0 )
@

<<label=total_phosphorus_table,echo=FALSE,results=tex>>=
    library(xtable)
    print(xtable(ptot_tot_percentages, caption="Proportion of total phosphorus loading contributed by each type of event",
                 label="tab:ptot", align=c('l', 'c', 'c')), 
          caption.placement="bottom", hline.after=0 )
@

\subparagraph{Snowmelt-driven events}
Since sediment and phosphorus are carried into streams by runoff, it makes intuitive sense that the amount of loading during an event should depend on the amount of runoff during that event. In the case of rainfall-driven loading events, it is straightforward to use rain gauges to measure the amount of water entering the stream system. In the case of snowmelt-driven loading events, though, it is not easy to measure how much water melts out of the snowpack, especially when there is also additional snow falling at the same time. There is a subset of events for which we are able to estimate the amount of melting water: Those are the events when we have a measurement of the snow's water content and of the snow depth both before and after the event, and no additional snow falls during the event.\\

We would like to make a model that uses the available event data to describe the amount of sediment and phosphorus loading. In order to use our estimate of the snowmelt as a predictor of loading, we must ignore the snowmelt-driven events for which we cannot estimate the snowmelt. In order to determine whether that will bias our results, we first look at the overall proportion of loading that is provided by the events we will not be modeling.\\

<<label=ignored_snowmelt_props, echo=FALSE, results=tex>>=
    library(xtable)
        
    ignored_props = matrix( nrow=length(streams), ncol=2 )
    for(i in 1:length(streams))
    {
    	stream = get(streams[i])
		ignored_props[i,] = sapply(c("stot_tot", "ptot_tot"), function(x) sum(stream[is.na(stream$total_water), x], na.rm=T) / sum(stream[,x], na.rm=T))
    }
    ignored_props = data.frame(ignored_props)
    names(ignored_props) = c("Sediment", "Phosphorus")
    row.names(ignored_props) = sapply(streams, function(x) get(x=x, pos=stream_names))
@

We can also compare the size of events that will be ignored versus the size of events that will be modeled. The p-values of the tests comparing the sediment and phosphorus loads from each event at each stream are tabulated in table \ref{tab:ignored_test1}.\\

<<label=ignored_snowmelt_test1, echo=FALSE, results=tex>>=
    library(xtable)
    ignored_tests1 = matrix( nrow=length(streams), ncol=2 )
    
    for(i in 1:length(streams))
    {
        stream = get(streams[i])
        ignored_tests1[i,] = sapply(c("stot_tot", "ptot_tot"), function(x) wilcox.test(stream[is.na(stream$total_water) & stream$snow==TRUE, x],
                                                                                       stream[!is.na(stream$total_water) & stream$snow==TRUE, x])$p.value)
    }
    ignored_tests1 = data.frame(ignored_tests1)
    names(ignored_tests1) = c("Sediment", "Phosphorus")
    row.names(ignored_tests1) = sapply(streams, function(x) get(x=x, pos=stream_names))

    print(xtable(ignored_tests1, caption="P-values of tests of the difference in the load contributed by ignored and modeled snowmelt-driven events.", 
                 digits=3, label="tab:ignored_test1", align=c('l', 'c', 'c')), caption.placement="bottom", hline.after=0)
@

Finally, we compare the dates when the ignored events occured to the dates when the modeled events occured. The p-values for the test at each stream are tabulated in Table \ref{tab:ignored_test2}.\\

<<label=ignored_snowmelt_test2, echo=FALSE, results=tex>>=
    library(xtable)
    ignored_tests2 = matrix( nrow=length(streams), ncol=1 )
    
    for(i in 1:length(streams))
    {
        stream = get(streams[i])
        ignored_tests2[i,] = sapply(c("sin_julian"), function(x) wilcox.test(stream[is.na(stream$total_water) & stream$snow==TRUE, x],
                                                                             stream[!is.na(stream$total_water) & stream$snow==TRUE, x])$p.value)
    }
    ignored_tests2 = data.frame(ignored_tests2)
    names(ignored_tests2) = c("p-value")
    row.names(ignored_tests2) = sapply(streams, function(x) get(x=x, pos=stream_names))

    print(xtable(ignored_tests2, caption="P-values of tests of the difference in the date of modeled snowmelt-driven events compared to the ignored events.",
                 digits=3, label="tab:ignored_test2", align=c('l', 'c')), caption.placement="bottom", hline.after=0)
@

in most cases there is not a statistically significant difference in size or date between the events for which \verb+total_water+ is known, and those for which it is not. It therefore looks like the model results won't be badly biased by ignoring the events for which we don't have an estimate of the snowmelt.\\

\subparagraph{Major events}
Over the course of the monitoring period, the majority of the total load (both of sediment and of phosphorus) was carried during just a few major events. Just 10\% of the events carried between \Sexpr{round( 100*min(q_90$stot_tot), 1 )}\% (at \Sexpr{stream_names[[names(which.min(q_90$stot_tot))]]}) and \Sexpr{round( 100*max(q_90$stot_tot), 1 )}\% (at \Sexpr{stream_names[[names(which.max(q_90$stot_tot))]]}) of the total sediment load; the same events produced between \Sexpr{round( 100*min(q_90$ptot_tot), 1 )}\% (at \Sexpr{stream_names[[names(which.min(q_90$ptot_tot))]]}) and \Sexpr{round( 100*max(q_90$ptot_tot), 1 )}\% (at \Sexpr{stream_names[[names(which.max(q_90$ptot_tot))]]}) of the total phosphorus load.\\


<<label=breakdown_major_events_rain_or_snow, echo=False>>=
    prp_major = proportions(streams, "stot_tot_major", col.names=c("snowmelt-driven", "rainfall-driven"))
    prp_all = proportions(streams, "event", col.names=c("snowmelt-driven", "rainfall-driven"))
@


\begin{table}[h] \small
    \begin{center}
    \begin{tabular}{lrl}
    \textbf{Sediment} & $R^2$ & Model terms \\
    \hline
<<sediment_selection_table, echo=False, include=True, results=tex>>=
R2_table(es)
R2_table(js)
R2_table(os)
R2_table(bs)
R2_table(gs)
R2_table(ks)
R2_table(rs)
R2_table(bows)
R2_table(as)
@
    \end{tabular}
    \caption{Results of variable selection for a model of sediment loading from rainfall-driven events\label{sed_r_square_nosnow}}
    \end{center}
\end{table}

\begin{table}[h] \small
    \begin{center}
    \begin{tabular}{lrl}
    \textbf{Phosphorus} & $R^2$ & Model terms \\
    \hline
<<phosphorus_selection_table, echo=False, include=True, results=tex>>=
R2_table(ep)
R2_table(jp)
R2_table(op)
R2_table(bp)
R2_table(gp)
R2_table(kp)
R2_table(rp)
R2_table(bowp)
R2_table(ap)
@
    \end{tabular}
    \caption{Results of variable selection for a model of phosphorus loading from rainfall-driven events\label{phos_r_square_nosnow}}
    \end{center}
\end{table}


\begin{table}[h] \small
    \begin{center}
    \begin{tabular}{lrl}
    \textbf{Sediment} & $R^2$ & Model terms \\
    \hline
<<sediment_selection_table, echo=False, include=True, results=tex>>=
R2_table(es_snow2)
R2_table(js_snow2)
R2_table(os_snow2)
R2_table(bs_snow2)
R2_table(gs_snow2)
R2_table(ks_snow2)
R2_table(rs_snow2)
R2_table(bows_snow2)
R2_table(as_snow2)
@
    \end{tabular}
    \caption{Results of variable selection for a model of sediment loading from snowmelt-driven events.\label{sed_r_square_snow}}
    \end{center}
\end{table}



\begin{table}[h] \small
    \begin{center}
    \begin{tabular}{lrl}
    \textbf{Phosphorus} & $R^2$ & Model terms \\
    \hline
<<phosphorus_selection_table, echo=False, include=True, results=tex>>=
R2_table(ep_snow2)
R2_table(jp_snow2)
R2_table(op_snow2)
R2_table(bp_snow2)
R2_table(gp_snow2)
R2_table(kp_snow2)
R2_table(rp_snow2)
R2_table(bowp_snow2)
R2_table(ap_snow2)
@
    \end{tabular}
    \caption{Results of variable selection for a model of phosphorus loading from snowmelt-driven events.\label{phos_r_square_snow}}
    \end{center}
\end{table}


\section{Analysis}

\subsection{Variable selection}
In order to make a model of the load carried by the stream, we need to select the predictor variables that have explanatory power. We used stepwise regression with the Bayesian Information Criterion (BIC) to screen the potential predictor variables. We begin the selection with an intercept-only model, and at each step we add or remove one variable. The variable that is added or removed is the one whose addition or removal will do the most to reduce the BIC. If no such variable is found, then selection is considered complete.\\

\paragraph{Rainfall-driven events}

The predictors that survived the screening at each stream are listed in Table \ref{nosnow_predictor_list}. The variables are listed in the order of their importance to the model.\\

\begin{table}[h!]\small
    \begin{center}
    \begin{tabular}{ll}
        \textbf{Solids} & \\
        \hspace{5mm} Eagle: & \Sexpr{ sanipaste2(es$ranked, collapse=", ") }\\
        \hspace{5mm} Joos: & \Sexpr{ sanipaste2(js$ranked, collapse=", ") }\\
        \hspace{5mm} Otter: & \Sexpr{ sanipaste2(os$ranked, collapse=", ") }\\
        \hspace{5mm} Brewery: & \Sexpr{ sanipaste2(bs$ranked, collapse=", ") }\\
        \hspace{5mm} Garfoot: & \Sexpr{ sanipaste2(gs$ranked, collapse=", ") }\\
        \hspace{5mm} Kuenster: & \Sexpr{ sanipaste2(ks$ranked, collapse=", ") }\\
        \hspace{5mm} Rattlesnake: & \Sexpr{ sanipaste2(rs$ranked, collapse=", ") } \\
        \hspace{5mm} Bower: & \Sexpr{ sanipaste2(bows$ranked, collapse=", ") }\\
        \hspace{5mm} Aggregate: & \Sexpr{ sanipaste2(as$ranked, collapse=", ") }
    \vspace{2mm}\\
        \textbf{Phosphorus} & \\
        \hspace{5mm} Eagle: & \Sexpr{ sanipaste2(ep$ranked, collapse=", ") }\\
        \hspace{5mm} Joos: & \Sexpr{ sanipaste2(jp$ranked, collapse=", ") }\\
        \hspace{5mm} Otter: & \Sexpr{ sanipaste2(op$ranked, collapse=", ") }\\
        \hspace{5mm} Brewery: & \Sexpr{ sanipaste2(bp$ranked, collapse=", ") }\\
        \hspace{5mm} Garfoot: & \Sexpr{ sanipaste2(gp$ranked, collapse=", ") }\\
        \hspace{5mm} Kuenster: & \Sexpr{ sanipaste2(kp$ranked, collapse=", ") }\\
        \hspace{5mm} Rattlenake: & \Sexpr{ sanipaste2(rp$ranked, collapse=", ") }\\
        \hspace{5mm} Bower: & \Sexpr{ sanipaste2(bowp$ranked, collapse=", ") }\\
        \hspace{5mm} Aggregate: & \Sexpr{ sanipaste2(ap$ranked, collapse=", ") }\\
    \end{tabular}
    \caption{The most important variables in the models for rainfall-driven loading. The variables are ordered by their importance to the model of the load. \label{nosnow_predictor_list}}
    \end{center}
\end{table}

In each case, the two most important predictors are the theisen rainfall and the antecedent baseflow. Using just those two predictors results in an $R^2$ greater than 0.7 in most models (see Tables \ref{sed_r_square_nosnow} and \ref{phos_r_square_nosnow}.) Since the antecedent baseflow is considered an indicator of how much water is in the watershed before each event, we conclude that the amount of sediment and phosphorus washed into a stream by each event is mainly a function of the quantity of water moving through the system. At Brewery Creek, the intensity of rainfall is a more important predictor than the total quantity of rain.\\

The performance of the global (aggregate) model is quite good: with just two predictors (sediment: \Sexpr{paste(as$ranked[1:2], sep=", ")}, phosphorus: \Sexpr{paste(ap$ranked[1:2], sep=", ")}) the $\text{R}^2$ is \Sexpr{round(as$R2[2], 2)} and \Sexpr{round(ap$R2[2], 2)}, respectively. In the case of sediment, the next-most-important predictor is the stream slope. Including it in the model pushes the $\text{R}^2$ to \Sexpr{round(ap$R2[3], 2)}.\\

\paragraph{Snowmelt-driven events} We had less success modeling the loading produced by the snowmelt-driven events. The predictors that survived the screening process were different from stream to stream and those variables that did survive at most sites weren't always selected in the same order (like they were for the rainfall-driven events). What's more, the models for snowmelt-driven events were less accurate than for rainfall-driven events, ranging in $R^2$ from 0.24 to 0.53, with most in the 0.45 range.\\

At most sites, the most important predictor was a temperature measurement, either the maximum or the mean temperature during the loading event. The antecedent baseflow also appears to be important at most sites. It seems likely that, as in the case of rainfall-driven events, the loading is driven by the quantity of water that moves through the watershed during the event.\\

\begin{table}[h!]\small
    \begin{center}
    \begin{tabular}{ll}
        \textbf{Solids} & \\
        \hspace{5mm} Eagle: & \Sexpr{ sanipaste2(es_snow2$ranked, collapse=", ") }\\
        \hspace{5mm} Joos: & \Sexpr{ sanipaste2(js_snow2$ranked, collapse=", ") }\\
        \hspace{5mm} Otter: & \Sexpr{ sanipaste2(os_snow2$ranked, collapse=", ") }\\
        \hspace{5mm} Brewery: & \Sexpr{ sanipaste2(bs_snow2$ranked, collapse=", ") }\\
        \hspace{5mm} Garfoot: & \Sexpr{ sanipaste2(gs_snow2$ranked, collapse=", ") }\\
        \hspace{5mm} Kuenster: & \Sexpr{ sanipaste2(ks_snow2$ranked, collapse=", ") }\\
        \hspace{5mm} Rattlesnake: & \Sexpr{ sanipaste2(rs_snow2$ranked, collapse=", ") } \\
        \hspace{5mm} Bower: & \Sexpr{ sanipaste2(bows_snow2$ranked, collapse=", ") }\\
        \hspace{5mm} Aggregate: & \Sexpr{ sanipaste2(as_snow2$ranked, collapse=", ") }
    \vspace{2mm}\\
        \textbf{Phosphorus} & \\
        \hspace{5mm} Eagle: & \Sexpr{ sanipaste2(ep_snow2$ranked, collapse=", ") }\\
        \hspace{5mm} Joos: & \Sexpr{ sanipaste2(jp_snow2$ranked, collapse=", ") }\\
        \hspace{5mm} Otter: & \Sexpr{ sanipaste2(op_snow2$ranked, collapse=", ") }\\
        \hspace{5mm} Brewery: & \Sexpr{ sanipaste2(bp_snow2$ranked, collapse=", ") }\\
        \hspace{5mm} Garfoot: & \Sexpr{ sanipaste2(gp_snow2$ranked, collapse=", ") }\\
        \hspace{5mm} Kuenster: & \Sexpr{ sanipaste2(kp_snow2$ranked, collapse=", ") }\\
        \hspace{5mm} Rattlesnake: & \Sexpr{ sanipaste2(rp_snow2$ranked, collapse=", ") }\\
        \hspace{5mm} Bower: & \Sexpr{ sanipaste2(bowp_snow2$ranked, collapse=", ") }\\
        \hspace{5mm} Aggregate: & \Sexpr{ sanipaste2(ap_snow2$ranked, collapse=", ") }\\
    \end{tabular}
    \caption{The most important variables in the models for snowmelt-driven loading. The variables are ordered by their importance to the model of the load. \label{snow_predictor_list}}
    \end{center}
\end{table}

\section{Conclusions}
We have an accurate global model that describes the loading that will result from a rainstorm, based just on the base flow before the storm and on the amount of rain that falls during the storm. Antecedent base flow is a measurement of how much water is in the watershed before a storm and any new water comes as rainfall, so it seems that the sediment and phosphorus loads are driven mainly by the quantity of water moving through the watershed. The stream slope also seems to be important; that could be because steeper slopes give surface water less time to infiltrate and therefore increase the intensity of a rainfall event.\\

We have not yet found an accurate way to model the amount of load during a snowmelt-driven event but we have seen that the air temperature (which drives snowmelt), the antecedent base flow, and the amount of additional precipitation are important predictors for those events.\\

Most of the annual loading seems to be produced by a few major events. If the goal is to reduce the impact of sediment and phosphorus loading on stream health, then something must be done to mitigate the impact of those major events. Figures \ref{cdf-s} and \ref{cdf-p} make it look like the majority of the ranfall-driven loading comes from storms that drop at least two inches of rain. Mitigating the effect of large storms will probably require slowing the water's movement through the watershed - for instance, by impounding runoff before it can flow into the creeks. A further analysis should look at the frequency of big storms in order to get an idea of how quickly impounded water must be dealt with in order to be ready for the next event.\\


\begin{figure}
    \begin{center}
<<label=figure2, fig=True, echo=False, width=6, height=5>>=
<<cumulative_sloading_by_rainfall>>
@
    \end{center}
    \caption{Proportion of the total sediment load contributed by rainfall events up to the size shown. Snowmelt-driven events are excluded.\label{cdf-p}}
\end{figure}

\begin{figure}
    \begin{center}
<<label=figure3, fig=True, echo=False, width=6, height=5>>=
<<cumulative_ploading_by_rainfall>>
@
    \end{center}
    \caption{Proportion of the total phosphorus load contributed by rainfall events up to the size shown. Snowmelt-driven events are excluded.\label{cdf-s}}
\end{figure}

\begin{figure}
    \begin{center}
<<label=figure4, fig=True, echo=False, width=12, height=15>>=
<<bubble_plots>>
@
    \end{center}
    \caption{Antecedent base flow is the horizontal axis; theisen rainfall is the vertical axis. Each dot represents one event. The size of the dot shows the total sediment load contributed by that event. \label{bubbles}}
\end{figure}

<<label=guide, echo=False, results=tex, include=False, eval=False>>=
    stream = "eagle"
    stream = get(stream)
    
    snow = stream[stream$snow==TRUE,]
    guide(stot_tot~nws_prec + total_water + nws_snow + melt_snow + tmean + tmax + tmin + sweq + julian + sin_julian + cos_julian,
          data=snow, sweave=T, cv_gain=0)
    
    rain = stream[stream$snow==FALSE,]
    guide(stot_tot~nws_prec+event_type+ap_1day+ap_2day+ap_3day+total_water+theisen+sweq+julian+sin_julian+cos_julian+tmean+tmax+tmin,
          data=rain, sweave=T, cv_gain=0)
@

\bibliographystyle{plain}
\bibliography{../references/loadings}

\end{document}
