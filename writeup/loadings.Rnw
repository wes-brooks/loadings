\documentclass[10pt]{article}
\usepackage{geometry}                % See geometry.pdf to learn the layout options. There are lots.
\geometry{letterpaper}                   % ... or a4paper or a5paper or ... 
%\geometry{landscape}                % Activate for for rotated page geometry
\usepackage[parfill]{parskip}    % Activate to begin paragraphs with an empty line rather than an indent
\usepackage[cm]{fullpage}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage[margin=20pt, font=small, labelfont=sc, labelsep=endash]{caption}
\usepackage{subfig}
\usepackage{multirow}
\usepackage{amstext}
\usepackage{verbatim}
%\usepackage{pstricks, pst-node,pst-tree}


\title{Analysis of loadings}
\author{Wesley Brooks}
\date{}                                           % Activate to display a given date or no date

\begin{document}
\SweaveOpts{concordance=TRUE, echo=FALSE, include=FALSE}
\setkeys{Gin}{width=0.9\textwidth}    %make figures a bit wider than the Sweave default.
\maketitle

<<setup, echo=FALSE, include=FALSE, cache=FALSE>>=
    library(knitr)
    opts_chunk$set(cache.path='cache/', autodep=TRUE, echo=FALSE, include=FALSE)
    options(replace.assign=TRUE)
@

<<read_data>>=
    #Read data into R and do some basic manipulation to get it into a usable format:
    setwd('c:/Users/wrbrooks/git/loadings/writeup')
    source('c:/Users/wrbrooks/git/loadings/code/guide.r')
    streams = c('eagle', 'joosvalley', 'otter', 'brewery', 'garfoot', 'kuenster', 'rattlesnake', 'bower')
    stream_names = list(eagle='Eagle', joosvalley='Joos', otter='Otter', bower='Bower',
                        brewery='Brewery', garfoot='Garfoot', kuenster='Kuenster', rattlesnake="Rattlesnake", aggregate="Aggregate")
    outputs = c('sstorm_tot', 'sstorm_max', 'sstorm_avg', 'stot_tot', 'stot_max', 'stot_yield', 'ptot_yield', 
                    'stot_avg', 'pstorm_tot', 'pstorm_max', 'pstorm_avg', 'ptot_tot', 'ptot_max', 'ptot_avg')
    
    #Names of the NWS data files for each creek
    nws_files = list("eagle"=c("eagle/NWS/Winona_91-94_ASCII.txt", "eagle/NWS/Winona_03-07_ASCII.txt"),
                        "joosvalley"=c("eagle/NWS/Winona_91-94_ASCII.txt", "eagle/NWS/Winona_03-07_ASCII.txt"),
                        "otter"=c("otter/NWS/Sheboygan_Otter_raw.txt"),
                        "brewery"=c("brewery/NWS/Madison_SND.txt"),
                        "garfoot"=c("garfoot/NWS data/madison_daily.txt"),
                        "kuenster"=c("Kuenster/NWS data/Guttenberg_raw.txt"),
                        "rattlesnake"=c("Kuenster/NWS data/Guttenberg_raw.txt"),
                        "bower"=c("bower/NWS data/greenbay_raw.txt", "bower/NWS data/greenbaypost_raw.txt"))
    
    #Location of the raw loading data file for each creek
    daily_load_data = list()
    raw_load_files = list("eagle"=c("eagle/eagle_loads.txt"),
                        "joosvalley"=c("joosvalley/joos_loads.txt"),
                        "otter"=c("otter/otter_loads.txt"),
                        "brewery"=c("brewery/brewery_loads.txt"),
                        "garfoot"=c("garfoot/garfoot_loads.txt"),
                        "kuenster"=c("Kuenster/kuenster_loads.txt"),
                        "rattlesnake"=c("Rattlesnake/rattle_loads.txt"),
                        "bower"=c("bower/bower_loads.txt"))
    
    watersheds = read.csv("../data/watersheds.csv", header=T)
    
    #A list to hold the ecdf functions for antecedent base flow.
    flow_cdf = list()
    
    #loop through the streams, reading them in one by one
    for(stream_name in streams)
    {
        data_file = paste('../data/', stream_name, '/', stream_name, 'creek.csv', sep='')
        stream = read.csv(data_file, header=T, na.strings=c('NA', 'na')) 
        
        #read the daily flow file, which we use for antecedent moisture contitions
        daily_flow = paste("../data/", stream_name, "/", stream_name, "_q.out", sep="")
        head = strsplit( readLines(daily_flow)[1], "\t" )
        daily_flow = read.table(daily_flow, skip=2, col.names=unlist(head))
        daily_flow$DV_date = with( daily_flow, as.POSIXlt( as.character(DV_date), format="%m/%d/%Y" ) )
        
        #do some basic data transformations:
        stream = within( stream, {
            event_type <- factor(event_type)
            stot_yield <- stot_tot / watersheds$area[watersheds$stream==stream_name]
            ptot_yield <- ptot_tot / watersheds$area[watersheds$stream==stream_name]
            year <- factor(year)
            melt_snow[melt_snow=='N' | melt_snow=='Z' | melt_snow=='U'] <- NA
            melt_snow <- as.numeric(levels(melt_snow)[melt_snow])
            sweq <- as.numeric(sub("%", "e-2", sweq))
            ap_1day <- as.numeric(ap_1day)
            ap_3day <- as.numeric(ap_3day)
            ap_5day <- as.numeric(ap_5day) 
            tmax <- as.numeric(tmax)
            tmin <- as.numeric(tmin)
            tmean <- as.numeric(tmean)
            stream <- as.factor(stream_name)
            start_day <- as.POSIXlt( as.character(start_day), format="%m/%d/%Y" )
            year <- as.numeric(as.character(year))
            water_year <- ifelse(month>=10, year+1, year)
            julian <- start_day$yday + 1
            sin_julian <- sin(julian*2*pi/365 - 0.35)
            cos_julian <- cos(julian*2*pi/365 - 0.35)
            for(output in outputs)
                assign( paste('log_', output, sep=""), log10(get(output)+0.01) )
            m <- as.factor(ifelse(is.na(m),0,ifelse(m=='M','M',0)))
            event <- rep(1, length(m))
            area <- watersheds$area[watersheds$stream==stream_name]
            slope <- watersheds$slope[watersheds$stream==stream_name]
            urb <- watersheds$urb[watersheds$stream==stream_name]
            logit_urb = log((urb/100)/(1-(urb/100)))
            ag <- watersheds$ag[watersheds$stream==stream_name]
            logit_ag = log((ag/100)/(1-(ag/100)))
            forest <- watersheds$forest[watersheds$stream==stream_name]
            logit_forest = log((forest/100)/(1-(forest/100)))
            water <- watersheds$water[watersheds$stream==stream_name]
            wetland <- watersheds$wetland[watersheds$stream==stream_name]
            other <- watersheds$other[watersheds$stream==stream_name]
            })
    
        #Get the raw daily loads at each site
        daily_load = data.frame()
        for( raw_load_file in get(stream_name, pos=raw_load_files)) {
            raw_path = paste("../data/", raw_load_file, sep="")
            daily_load = rbind(daily_load, read.table(raw_path, na.strings=c("", "99999", "-1.23E+25"), header=TRUE))
        }
        daily_load$date = with(daily_load, as.POSIXlt(as.character(date), format="%m/%d/%Y"))
        daily_load_data[[stream_name]] = daily_load
        
        #Find the base flow that immediately preceded each event
        antecedent_qbase = rep(NA, length(stream$start_day))
        for( i in 1:length(antecedent_qbase) ) {
            #get the date just prior to row i (subtraction is in units of seconds)
            unmatched = identical(which( daily_flow$DV_date == stream$start_day[i]-86400 ), integer(0))
            antecedent_qbase[i] = ifelse(unmatched, NA, daily_flow[which( daily_flow$DV_date == stream$start_day[i]-86400 ), 'QGW_fixed']) }
        stream$antecedent_qbase = antecedent_qbase
    
        #flow_cdf[[stream_name]] = ecdf(antecedent_qbase)
        flow_cdf[[stream_name]] = ecdf(daily_flow$QGW_fixed)
        stream$antecedent_qbase_quantile = flow_cdf[[stream_name]](antecedent_qbase)
        stream$antecedent_qbase2 = antecedent_qbase / watersheds$area[watersheds$stream==stream_name]
        
        #Find the average air temperature in the days before the event:
        #first, read the raw air temperature data
        nws = data.frame()
        for( nws_file in get(stream_name, pos=nws_files)) {
            nws_path = paste("../data/", nws_file, sep="")
            nws = rbind(nws, read.csv(nws_path, na.strings=c("", "99999", "-1.23E+25", "null"), header=TRUE))
        }
        nws$date = with(nws, ISOdate(year=year, month=month, day=day))
    
        #Now find the antecedent air temperature for each event
        #We will compute the mean, min, and range of air temps before this event began.
        antecedent_tmean = rep(NA, length(stream$start_day))
        antecedent_trange = rep(NA, length(stream$start_day))
        antecedent_tmax = rep(NA, length(stream$start_day))
        period = 2 #how far back in days to do the averaging
        for(i in 1:length(antecedent_tmean)) {
            to_average = which(nws$date < stream$start_day[i] & nws$date >= stream$start_day[i] - period*86400)
            antecedent_tmean[i] = mean(nws$Tmean[to_average], na.rm=TRUE)
            antecedent_tmax[i] = max(nws$Tmean[to_average], na.rm=TRUE) 
            antecedent_trange[i] = diff(range(nws$Tmean[to_average], na.rm=TRUE))
        }
        stream$antecedent_tmean = antecedent_tmean
        stream$antecedent_tmax = ifelse(antecedent_tmax>-Inf, antecedent_tmax, NA)
        stream$antecedent_trange = ifelse(antecedent_trange>-Inf, antecedent_trange, NA)
    
        #Now add this stream's data to the frame.
        assign(stream_name, stream)
        assign(paste(stream_name, "_flow", sep=""), daily_flow)
    }
    
    #Now mark the class of each event (1:snowmelt-driven, 2:pre-vegetation, 3:post-vegetation)
    #We will gather all the data into one frame:
    aggregate = data.frame()
    
    #loop through the stream sites:
    for(stream_name in streams)
    {
    	stream = get(stream_name)
    
    	#Decide which events are snowmelt-driven:         
    	class = vector()
    	prev_class = 0
    	num_events = dim(stream)[1]
                    
    	#loop through the events                        
    	for(row in 1:num_events) {
    		#first look for the beginning of each year's snowmelt events
    		if(stream$m[row]=='M') {
    			class = c(class, 1)
    			prev_class = 1
            }
    		else if(prev_class==1 & (stream$month[row]>=10 | stream$julian[row]<=135)) {
    			class = c(class, 1)
    			prev_class = 1
            }
    		else {
    			class = c(class, 3)
    			prev_class = 3
            }
        }
    	
        #New way of separating the rainfall-driven and snowmelt-driven events, based on Mari's categories:
        stream$snow = ifelse(stream$event_type==1, 0, 1)
        
        assign(stream_name, stream)
        assign(paste(stream_name, "_nosnow", sep=""), stream[stream$snow==FALSE,])
        assign(paste(stream_name, "_snow", sep=""), stream[stream$snow==TRUE,])
        
        aggregate = rbind(aggregate, stream)   
        aggregate$stream = rep("aggregate", dim(aggregate)[1])
        aggregate_nosnow = aggregate[aggregate$snow==FALSE,]
        aggregate_snow = aggregate[aggregate$snow==TRUE,]
    }
@


<<bubble_function>>=
    bubble <- function(target, scale=0.25, fg="red", bg="red", cex.lab=1.5, cex.axis=2, cex.title=1.5, line.xaxis=1, las=0) {
        #The "_nosnow" dataframes exclude the snowfall-influenced events.
        num_rows = ceiling(length(streams)/2)
        layout(matrix(1:(2*num_rows), num_rows, 2))
        par(mar=c(3,2,1,1)+0.1, oma=c(3,4,1,1), ann=FALSE)
        
        for(stream_name in streams) {
            #Retrieve the data frame for this stream
            stream = get(stream_name)
            
            #Produce the bubble plots
            symbols(stream[stream$snow==FALSE,]$antecedent_qbase,
                    stream[stream$snow==FALSE,]$theisen,
                    circles=sqrt(stream[stream$snow==FALSE,target]),
                    inches=scale, fg=fg, bg=bg, bty='n',
                    xlim=c(0, max(stream$antecedent_qbase, na.rm=TRUE)*1.2),
                    ylim=c(0, max(stream$theisen, na.rm=TRUE)*1.2),
                    xaxt='n', yaxt='n')
            
            axis(side=1, cex.axis=cex.axis, las=las, mgp=c(3,line.xaxis,0))
            axis(side=2, cex.axis=cex.axis, las=las)
            
            mtext(stream_names[[stream_name]], side=3, line=-9, cex=cex.title,
                  at=0.75*max(stream$antecedent_qbase, na.rm=TRUE) )
        }
        
        mtext("Antecedent baseflow (Cfs[?])", side=1, line=1, cex=cex.lab, at=NA, outer=TRUE)
        mtext("Theisen rainfall (in)", side=2, line=2, cex=cex.lab, at=NA, outer=TRUE)
    }
@


<<function_definitions>>=
    #Import the GAM library
    library(mgcv)
    
    #Backslash-escape special characters.
    sanitize <- function(str)
        gsub('([#$%&~_\\^\\\\{}])', '\\\\\\1', str, perl=TRUE)
    
    
    #Double-backslash-escape special characters.
    sanitize2 <- function(str)
        gsub('([#$%&~_\\^\\\\{}])', '\\\\\\\\\\1', str, perl=TRUE)
    
    
    #Paste together a list of strings, backslash-escaping special characters in each one.
    sanipaste <- function(pastelist, ...)
        paste(sanitize(pastelist), ...)
    
    
    #Paste together a list of strings, double-backslash-escaping special characers in each one.
    sanipaste2 <- function(pastelist, ...)
        paste(sanitize2(pastelist), ...)
    
    
    #Determine what proportion of loadings comes from each event class
    proportions <- function(streams, target, col.names) {
        result = matrix( nrow=length(streams), ncol=length(col.names))
    	for(i in 1:length(streams)) {
    		stream = get(streams[i])
    		result[i,] = sapply(c(TRUE, FALSE), function(x) sum(stream[stream$snow==x, target], na.rm=T) / sum(stream[,target], na.rm=T))
        }
        result = data.frame(result)
        names(result) = col.names
        row.names(result) = sapply(streams, function(x) get(x=x, pos=stream_names))
    	return(result)
    }
    
    
    #Determine what percentage of loadings comes from each event class
    percentages <- function(streams, target, col.names, decimals=1) {
        props = proportions(streams, target, col.names)
        result = matrix( nrow=0, ncol=length(col.names) )
        rows = dim(props)[1]
        
        for(row in 1:rows) {
            result = rbind( result, paste( ifelse(round(props[row,]*100, decimals)%%1 == 0 & decimals > 0,
                paste(as.character( round(props[row,]*100, 0) ), ".0", sep=""),
                as.character( round(props[row,]*100, decimals) )), "%", sep="" ))
        }
        result=data.frame(result)
        names(result) = names(props)
        row.names(result) = row.names(props)
        return(result)
    }
    
    
    #Extracts the terms in the model formula.
    parse_args <- function(model)
        return(attr(model$model, 'names'))
    
    
    #Compute the model's R**2.
    r2 <- function(model) {
        actual = model$residual+model$fitted
        rss = sum(model$residual**2)
        tss = sum((actual-mean(actual))**2)
        return(1 - rss/tss)
    }
    
    
    #Adds variables one-by-one to the model, finding the R^2 at each step.
    r2_step <- function(model, variables, data) {
        output = attr(model$model, "names")[1]
        call = paste(output, "~", variables[1], sep="")
        
        r_square = vector()
    
        for(variable in variables[-1]) {
            f = as.formula(call)
            model = lm(formula=f, data=data)
            r_square = c(r_square, r2(model))
            call = paste(call, "+", variable)
        }
        
        model = update(model, formula=call)
        r_square = c(r_square, r2(model))
        
        return(r_square)
    }
    
    
    #This function uses the BIC to screen variables, returning the 'step' object.
    stepwise_BIC <- function(target, data, sites) {
        predictors_raw = c("num_events", "theisen", "p5max", "p10max", "p15max", "p30max", "p60max",
                       "ei", "duration", "ap_1day", "ap_3day", "ap_5day", "tmax", "tmean", "tmin", "antecedent_qbase_quantile", 
                       "nws_prec", "nws_snow", "melt_snow", "cos_julian", "sin_julian",
                       "antecedent_tmean", "antecedent_tmax", "antecedent_trange", "slope", "area")
        d = data[,c(target, predictors_raw)]
        result = list()
        
        predictors = c(predictors_raw, "slope:theisen", "slope:antecedent_qbase_quantile", "slope:duration", "slope:area")
        full_model = as.formula( paste(target, "~", paste(predictors, collapse="+")) )
        intercept_only = as.formula( paste(target, "~1") )
        fm1 <- lm(full_model, data=d, x=T)
        
        d = data.frame(cbind(target=fm1$fitted+fm1$residual, fm1$x))
        names(d)[1] = target
        fm2 <- lm(intercept_only, data=d)
        screened = step(fm2, scope=full_model, direction='both', k=log(dim(d)[1]), trace=FALSE)
        
        terms = parse_args(screened)
        target = terms[1]
        predictors = terms[-1]
        formula = as.formula(paste(target, "~", paste(predictors, collapse="+")))
        
        model = lm(formula, data=data, x=T)
        
        #Put the results in a list object
        result$site = sites[[as.character(unique(data$stream)[1])]]
        result$model = model
        result$ranked = names(model$model)[-1] # rank_predictors(model)
        result$R2 = r2_step(model, result$ranked, data)
        return(result)
    }
    
    
    #Use the BIC to screen the predictors that are available when snow is on the ground.
    stepwise_BIC_snow <- function(target, data, sites) {
        predictors_raw = c("num_days", "tmax", "tmean", "tmin", "nws_prec", "nws_snow", "antecedent_qbase_quantile", 
                       "cos_julian", "sin_julian", "antecedent_tmean", "antecedent_tmax", "antecedent_trange", "slope", "area")
        d = data[,c(target, predictors_raw)]
        result = list()
    
        predictors = c(predictors_raw, "slope:nws_prec", "slope:antecedent_qbase_quantile","slope:area")
        full_model = as.formula( paste(target, "~", paste(predictors, collapse="+")) )
        intercept_only = as.formula( paste(target, "~1") )
        fm1 <- lm(full_model, data=d, x=T)
        
        d = data.frame(cbind(target=fm1$fitted+fm1$residual, fm1$x))
        names(d)[1] = target
        fm2 <- lm(intercept_only, data=d)
        screened = step(fm2, scope=full_model, direction='both', k=log(dim(d)[1]), trace=FALSE)
        
        terms = parse_args(screened)
        target = terms[1]
        predictors = terms[-1]
        formula = as.formula(paste(target, "~", paste(predictors, collapse="+")))
        
        model = lm(formula, data=data, x=T)
        
        #Put the results in a list object
        result$site = sites[[as.character(unique(data$stream)[1])]]
        result$model = model
        result$ranked = names(model$model)[-1] #rank_predictors(model)
        result$R2 = r2_step(model, result$ranked, data)
        return(result)
    }
    
    
    #Use the BIC to screen the predictors that are available when snow is on the ground.
    stepwise_BIC_snow2 <- function(target, data, sites) {
        predictors_raw = c("num_days", "tmax", "tmean", "tmin", "nws_prec", "nws_snow", "total_water", "melt_water", "slope", "area", "antecedent_qbase_quantile",
                       "cos_julian", "sin_julian", "antecedent_tmean", "antecedent_tmax", "antecedent_trange")
        d = data[,c(target, predictors_raw)]
        result = list()
    
        predictors = c(predictors_raw, "antecedent_qbase_quantile:slope", "antecedent_qbase_quantile:area", "total_water:slope", "total_water:area")
        full_model = as.formula( paste(target, "~", paste(predictors, collapse="+")) )
        intercept_only = as.formula( paste(target, "~1") )
        fm1 <- lm(full_model, data=d, x=T)
        
        d = data.frame(cbind(target=fm1$fitted+fm1$residual, fm1$x))
        names(d)[1] = target
        fm2 <- lm(intercept_only, data=d)
        screened = step(fm2, scope=full_model, direction='both', k=log(dim(d)[1]), trace=FALSE)
        
        terms = parse_args(screened)
        target = terms[1]
        predictors = terms[-1]
        formula = as.formula(paste(target, "~", paste(predictors, collapse="+")))
        
        model = lm(formula, data=data, x=T)
        
        #Put the results in a list object
        result$site = sites[[as.character(unique(data$stream)[1])]]
        result$model = model
        result$ranked = names(model$model)[-1] #rank_predictors(model)
        result$R2 = r2_step(model, result$ranked, data)
        return(result)
    }
    
    
    #Function to flag the largest observations of a certain variable.
    major <- function(data, target, q=0.9, strata='') {
        #Flag the major events within each level of strata
        if(strata != '') {
            major = rep(0, length(data[,target]))
            
            #Loop through the strata
            for(stratum in unique(data[,strata])) {
                indx = which(data[,strata]==stratum)
                major[indx] = ifelse(data[indx,target] > quantile(data[indx,target], q, na.rm=TRUE), 1, 0)
            }
        }               
        else {
            #If no stratification is provided, then just flag the overall major events
            major = ifelse(data[,target]>quantile(data[,target], q, na.rm=TRUE), 1, 0)
        }
        
        #Either way, return the result
        return(major)
    }
    
    
    #Produce a boxplot of the per-event loading, showing rainfall- and snowmelt-driven events separately.
    bplot <- function(formula, data, loc, classes, site, ylim, horizontal=FALSE, site.names=TRUE, log='', ...) {
        boxplot(formula, data=data, bty='n', ylim=ylim, cex=0.6, pch=4, horizontal=horizontal, 
                boxwex=0.4, frame.plot=F, ann=F, names=classes, add=T, at=loc:(loc+1), yaxt='n', xaxt='n', log=log, ...)
        
        if (site.names)
            mtext(site, side=2, line=6.5, at=(loc+0.5), las=1, cex=0.9, adj=0)
        
        target = as.character(formula)[2]    
        target = paste(strsplit(target, "_", fixed=TRUE)[[1]][1], "_tot", sep="")
        mtext( paste(round(100*sum(data[data$snow==0,target], na.rm=TRUE)/sum(data[,target], na.rm=TRUE), 0), "%", sep=""), side=4, line=1.2, at=loc, las=1, adj=1 )
        mtext( paste(round(100*sum(data[data$snow==1,target], na.rm=TRUE)/sum(data[,target], na.rm=TRUE), 0), "%", sep=""), side=4, line=1.2, at=(loc+1), las=1, adj=1 )
    }
    
    
    #Produce a table that shows how the R**2 grows as new variables are added to the model.
    R2_table <- function(varlist) {
        numvars = length(varlist$R2)
        cat(paste("\\multirow{", as.character(numvars+1), "}{*}{", varlist$site, "}", sep=""))
        for(i in 1:numvars) {
            cat(paste(" & ", as.character(round(varlist$R2[i], 3)), " & ", sep=""))
            
            for(j in 1:i) {
                cat(sanitize(varlist$ranked[j]))
                if(j<i)
                    cat(" + ")
            }
            cat("\\\\ \n")
        }
        cat("\\vspace{2mm}\\\\ \n")
    }

    
@



<<variable_selection_nosnow>>=
    es = stepwise_BIC(target="log_stot_yield", data=eagle_nosnow, sites=stream_names)
    js = stepwise_BIC(target="log_stot_yield", data=joosvalley_nosnow, sites=stream_names)
    os = stepwise_BIC(target="log_stot_yield", data=otter_nosnow, sites=stream_names)
    bs = stepwise_BIC(target="log_stot_yield", data=brewery_nosnow, sites=stream_names)
    gs = stepwise_BIC(target="log_stot_yield", data=garfoot_nosnow, sites=stream_names)
    ks = stepwise_BIC(target="log_stot_yield", data=kuenster_nosnow, sites=stream_names)
    rs = stepwise_BIC(target="log_stot_yield", data=rattlesnake_nosnow, sites=stream_names)
    bows = stepwise_BIC(target="log_stot_yield", data=bower_nosnow, sites=stream_names)
    as = stepwise_BIC(target="log_stot_yield", data=aggregate_nosnow, sites=stream_names)
    
    ep = stepwise_BIC(target="log_ptot_yield", data=eagle_nosnow, sites=stream_names)
    jp = stepwise_BIC(target="log_ptot_yield", data=joosvalley_nosnow, sites=stream_names)
    op = stepwise_BIC(target="log_ptot_yield", data=otter_nosnow, sites=stream_names)
    bp = stepwise_BIC(target="log_ptot_yield", data=brewery_nosnow, sites=stream_names)
    gp = stepwise_BIC(target="log_ptot_yield", data=garfoot_nosnow, sites=stream_names)
    kp = stepwise_BIC(target="log_ptot_yield", data=kuenster_nosnow, sites=stream_names)
    rp = stepwise_BIC(target="log_ptot_yield", data=rattlesnake_nosnow, sites=stream_names)
    bowp = stepwise_BIC(target="log_ptot_yield", data=bower_nosnow, sites=stream_names)
    ap = stepwise_BIC(target="log_ptot_yield", data=aggregate_nosnow, sites=stream_names)
@

<<variable_selection_snow>>=
    es_snow = stepwise_BIC_snow(target="log_stot_yield", data=eagle_snow, sites=stream_names)
    js_snow = stepwise_BIC_snow(target="log_stot_yield", data=joosvalley_snow, sites=stream_names)
    os_snow = stepwise_BIC_snow(target="log_stot_yield", data=otter_snow, sites=stream_names)
    bs_snow = stepwise_BIC_snow(target="log_stot_yield", data=brewery_snow, sites=stream_names)
    gs_snow = stepwise_BIC_snow(target="log_stot_yield", data=garfoot_snow, sites=stream_names)
    ks_snow = stepwise_BIC_snow(target="log_stot_yield", data=kuenster_snow, sites=stream_names)
    rs_snow = stepwise_BIC_snow(target="log_stot_yield", data=rattlesnake_snow, sites=stream_names)
    bows_snow = stepwise_BIC_snow(target="log_stot_yield", data=bower_snow, sites=stream_names)
    as_snow = stepwise_BIC_snow(target="log_stot_yield", data=aggregate_snow, sites=stream_names)
    
    ep_snow = stepwise_BIC_snow(target="log_ptot_yield", data=eagle_snow, sites=stream_names)
    jp_snow = stepwise_BIC_snow(target="log_ptot_yield", data=joosvalley_snow, sites=stream_names)
    op_snow = stepwise_BIC_snow(target="log_ptot_yield", data=otter_snow, sites=stream_names)
    bp_snow = stepwise_BIC_snow(target="log_ptot_yield", data=brewery_snow, sites=stream_names)
    gp_snow = stepwise_BIC_snow(target="log_ptot_yield", data=garfoot_snow, sites=stream_names)
    kp_snow = stepwise_BIC_snow(target="log_ptot_yield", data=kuenster_snow, sites=stream_names)
    rp_snow = stepwise_BIC_snow(target="log_ptot_yield", data=rattlesnake_snow, sites=stream_names)
    bowp_snow = stepwise_BIC_snow(target="log_ptot_yield", data=bower_snow, sites=stream_names)
    ap_snow = stepwise_BIC_snow(target="log_ptot_yield", data=aggregate_snow, sites=stream_names)
@


<<variable_selection_snow2>>=
    es_snow2 = stepwise_BIC_snow2(target="log_stot_yield", data=eagle_snow, sites=stream_names)
    js_snow2 = stepwise_BIC_snow2(target="log_stot_yield", data=joosvalley_snow, sites=stream_names)
    os_snow2 = stepwise_BIC_snow2(target="log_stot_yield", data=otter_snow, sites=stream_names)
    bs_snow2 = stepwise_BIC_snow2(target="log_stot_yield", data=brewery_snow, sites=stream_names)
    gs_snow2 = stepwise_BIC_snow2(target="log_stot_yield", data=garfoot_snow, sites=stream_names)
    ks_snow2 = stepwise_BIC_snow2(target="log_stot_yield", data=kuenster_snow, sites=stream_names)
    rs_snow2 = stepwise_BIC_snow2(target="log_stot_yield", data=rattlesnake_snow, sites=stream_names)
    bows_snow2 = stepwise_BIC_snow2(target="log_stot_yield", data=bower_snow, sites=stream_names)
    as_snow2 = stepwise_BIC_snow2(target="log_stot_yield", data=aggregate_snow, sites=stream_names)
    
    ep_snow2 = stepwise_BIC_snow2(target="log_ptot_yield", data=eagle_snow, sites=stream_names)
    jp_snow2 = stepwise_BIC_snow2(target="log_ptot_yield", data=joosvalley_snow, sites=stream_names)
    op_snow2 = stepwise_BIC_snow2(target="log_ptot_yield", data=otter_snow, sites=stream_names)
    bp_snow2 = stepwise_BIC_snow2(target="log_ptot_yield", data=brewery_snow, sites=stream_names)
    gp_snow2 = stepwise_BIC_snow2(target="log_ptot_yield", data=garfoot_snow, sites=stream_names)
    kp_snow2 = stepwise_BIC_snow2(target="log_ptot_yield", data=kuenster_snow, sites=stream_names)
    rp_snow2 = stepwise_BIC_snow2(target="log_ptot_yield", data=rattlesnake_snow, sites=stream_names)
    bowp_snow2 = stepwise_BIC_snow2(target="log_ptot_yield", data=bower_snow, sites=stream_names)
    ap_snow2 = stepwise_BIC_snow2(target="log_ptot_yield", data=aggregate_snow, sites=stream_names)
@


<<breakdown_snow_or_rain>>=
    for(target in c('ptot_tot', 'pstorm_tot', 'stot_tot', 'sstorm_tot')) {
        p = percentages(streams, target, col.names=c("snowmelt-driven", "rainfall-driven"), decimals=0)
        pp = as.matrix( proportions(streams, target, col.names=c("snowmelt-driven", "rainfall-driven")) )
        
        variable_name = paste(target, "_percentages", sep="")
        variable_name2 = paste(target, "_proportions", sep="")
        
        assign(variable_name, value=p)
        assign(variable_name2, value=pp)
    }
@


<<barchart, echo=FALSE, include=FALSE>>=
    layout(matrix(1:4,2,2))
    colors <- gray.colors(dim(ptot_tot_proportions)[1])
    
    barplot(ptot_tot_proportions, beside=T, names.arg=c("snow","rain"), ylab="proportion of phosphorus")
    barplot(stot_tot_proportions, beside=T, names.arg=c("snow","rain"), ylab="proportion of solids")
    barplot(pstorm_tot_proportions, beside=T, names.arg=c("snow","rain"), ylab="proportion of phosphorus")
    barplot(sstorm_tot_proportions, beside=T, names.arg=c("snow","rain"), ylab="proportion of solids")
    legend(x="topleft", legend=streams, fill=colors, bty='n')
@



\begin{figure}[h!]
    \begin{center}
<<fig2, fig=TRUE, fig.width=6, fig.height=8.5, include=TRUE>>=
<<barchart>>
@
    \end{center}
    \vspace{-10mm}
    \caption{Cumulative storm loadings at the four creeks.\label{bars}}
\end{figure}


<<boxplots>>=
    yy = c(10**-2.5, 10**2.8)
    xx = c(2, 3*length(streams) + 1)
    plot.new()
    par(mfcol=c(1,2), mar=c(4, 4, 1, 1), oma=c(0,3,1,0))
    plot.window(xlim=yy, ylim=xx)
    
    par(mfg=c(1,1))
    axis(side=1, cex=0.8)
    title(xlab="log sediment yield (log tons / mi^2)", line=2.2, cex=0.8)
    
    
    
    for(i in 1:length(streams))
    {
        #Put in the count of rainfall and snowmelt events
        data = get(streams[i])
        mtext(paste("Rainfall: ", length(data$snow)-sum(data$snow), sep=""), side=2, line=-1.7, at=3*i-0.1, las=1, adj=1, cex=0.8 )
        mtext(paste("Snowmelt: ", sum(data$snow), sep=""), side=2, line=-1.7, at=(3*i+1.1), las=1, adj=1, cex=0.8 )
        
        #Plot the boxplots of sediment yields
        site = stream_names[[streams[i]]]
        bplot(stot_yield~snow, data=data, loc=3*i, classes=c("snow","rain"), site=site, xlim=xx, ylim=yy, horizontal=TRUE, site.names=TRUE, log='y')
    }
    mtext("count:", side=3, line=0, at=yy[1], adj=0.6 )
    mtext("proportion:", side=3, line=0, at=yy[2], adj=0.39 )
    mtext("Sediment", side=3, line=0.8, at=mean(yy), cex=1.2 )

    yy = c(10**-2.5, 10**3.1)
    par(mfg=c(1,2), mar=c(4, 1.6, 1, 3.5), oma=c(0,0,1,1.5))
    plot.window(xlim=yy, ylim=xx)
    title(xlab="log phosphorus yield (log pounds / mi^2)", line=2.2, cex=0.8)
    axis(side=1, cex=0.8)
    
    for(i in 1:length(streams))
    {
        data = get(streams[i])
        site = stream_names[[streams[i]]]
        bplot(ptot_yield~snow, data=data, loc=3*i, classes=c("snow","rain"), site=site, xlim=xx, ylim=yy, horizontal=TRUE, site.names=FALSE, log='y')
    }
    
    mtext("proportion:", side=3, line=0, at=yy[2], adj=0.35 )
    mtext("Phosphorus", side=3, line=0.8, at=mean(yy), cex=1.2 )
@

<<cumulative-sediment-boxplots>>=
    nsites = length(streams)
    nrow = (nsites %/% 2) + (nsites %% 2)
    ncol = 2
    plot.new()
    par(mar=c(4, 4, 2, 1), oma=c(0,3,1,0), cex.axis=0.8)
    layout(matrix(1:(nrow*ncol), nrow, ncol))
    
    for (site.name in streams) {
        site = get(site.name)
        
        tot = list()
        for (y in unique(site[!is.na(site$stot_tot),'water_year'])) {
            annual = site[site$water_year==y & !is.na(site$stot_tot),]
            tot[[as.character(y)]] = cumsum(sort(annual$stot_tot, decreasing=TRUE))*100 / sum(annual$stot_tot)
        }
    
        boxframe = data.frame()
        for (i in 1:length(tot)) {
            boxframe = rbind(boxframe, cbind(1:length(tot[[i]]), tot[[i]]))
        }
        names(boxframe) = c('rank', 'cumsum')
        
        depth = max(sapply(tot, length))
        xx = c(1, depth)
        yy = c(0,100)
        ticks = seq(0, round(depth+0.1, -1), by=10)
        ticks[1] = 1
        
        boxplot(cumsum~rank, data=boxframe, frame.plot=FALSE, xlim=xx, ylim=yy, range=0, xaxt='n', yaxt='n')
        title(main=stream_names[[site.name]], line=0.2)
        
        axis(side=1, at=ticks, line=0)
        title(xlab='event annual rank', line=2.2)
        
        axis(side=2, at=seq(0, 100, by=25), line=0)
        title(ylab='percent annual load', line=2.2)    
    }
@

<<cumulative-phosphorus-boxplots>>=    
    nsites = length(streams)
    nrow = (nsites %/% 2) + (nsites %% 2)
    ncol = 2
    plot.new()
    par(mar=c(4, 4, 2, 1), oma=c(0,3,1,0), cex.axis=0.8)
    layout(matrix(1:(nrow*ncol), nrow, ncol))
    
    for (site.name in streams) {
        site = get(site.name)
        
        tot = list()
        for (y in unique(site[!is.na(site$ptot_tot),'water_year'])) {
            annual = site[site$water_year==y & !is.na(site$ptot_tot),]
            tot[[as.character(y)]] = cumsum(sort(annual$ptot_tot, decreasing=TRUE))*100 / sum(annual$ptot_tot)
        }
    
        boxframe = data.frame()
        for (i in 1:length(tot)) {
            boxframe = rbind(boxframe, cbind(1:length(tot[[i]]), tot[[i]]))
        }
        names(boxframe) = c('rank', 'cumsum')
        
        depth = max(sapply(tot, length))
        xx = c(1, depth)
        yy = c(0,100)
        ticks = seq(0, round(depth+0.1, -1), by=10)
        ticks[1] = 1
        
        boxplot(cumsum~rank, data=boxframe, frame.plot=FALSE, xlim=xx, ylim=yy, range=0, xaxt='n', yaxt='n')
        title(main=stream_names[[site.name]], line=0.2)
        
        axis(side=1, at=ticks, line=0)
        title(xlab='event annual rank', line=2.2)
        
        axis(side=2, at=seq(0, 100, by=25), line=0)
        title(ylab='percent annual load', line=2.2)    
    }
@



%Boxplots of the contribution from individual storm events
\begin{figure}[h]
    \begin{center}
<<show_boxplots, fig=TRUE, fig.width=8, fig.height=10, include=TRUE>>=
<<boxplots>>
@
    \caption{Boxplots showing the sediment and phosphorus load produced by individual events at all four streams.\label{boxplots}}
    \end{center}
\end{figure}


%Cumulative sediment loading by event rank
\begin{figure}[h]
    \begin{center}
<<show-cumulative-sediment-boxplots, fig=TRUE, fig.width=8, fig.height=10, include=TRUE>>=
<<cumulative-sediment-boxplots>>
@
    \caption{Boxplots showing how the annual sediment loads were distributed by event rank at each site.\label{cumulative-sediment-boxplots}}
    \end{center}
\end{figure}


%Cumulative phosphorus loading by event rank
\begin{figure}[h]
    \begin{center}
<<show-cumulative-phosphorus-boxplots, fig=TRUE, fig.width=8, fig.height=10, include=TRUE>>=
<<cumulative-phosphorus-boxplots>>
@
    \caption{Boxplots showing how the annual phosphorus loads were distributed by event rank at each site.\label{cumulative-phosphorus-boxplots}}
    \end{center}
\end{figure}


<<cumulative_loading_by_rainfall>>=
    cumulative <- function(cex.title=1.5, cex.lab=1.5, cex.legend=2, lwd=2, las=0, cex.axis=2, line.xaxis=1)
    {
        num_rows = ceiling(length(streams)/2)
        layout(matrix(1:(2*num_rows), num_rows, 2))
        par(mar=c(3,2,1,1)+0.1, oma=c(3,4,1,1))
        
        line_type=1
        color=1
        yy=c(0,1)
        xx = c(0,max(aggregate[aggregate$snow==FALSE,'theisen'], na.rm=T))
        
        for(stream in streams)
        {
            stream_data = get(stream)
            
            non_snow = stream_data[stream_data$snow==FALSE & !is.na(stream_data$ptot_tot) & !is.na(stream_data$stot_tot),]
            non_snow_sorted = non_snow[ order(non_snow$theisen) ,]
            sed = cumsum(non_snow_sorted$stot_tot)/sum(stream_data$stot_tot, na.rm=T)
            phos = cumsum(non_snow_sorted$ptot_tot)/sum(stream_data$ptot_tot, na.rm=T)
            
            plot( x=non_snow_sorted$theisen, y=sed, type='l',lwd=lwd,
                lty=1, col=color, bty='n', ylim=yy, xlim=xx, axes=FALSE)
            par(new=T, ann=F)
            plot( x=non_snow_sorted$theisen, y=phos, type='l', lwd=lwd,
                lty=2, col=color, bty='n', ylim=yy, xlim=xx, axes=FALSE)
            
            legend(x='topleft', bty='n', legend=c("sediment", "phosphorus"), lty=1:2, cex=cex.legend, lwd=lwd)
            mtext(stream_names[[stream]], side=3, line=-3, cex=cex.title, at=0.55*xx[2] )
            par(new=F, ann=T, xaxt='s', yaxt='s')
            
            axis(side=1, at=seq(xx[1], xx[2], by=2), cex.axis=cex.axis, las=las, mgp=c(3,line.xaxis,0))
            axis(side=2, at=c(0, 0.5, 1), cex.axis=cex.axis, las=las)
        }
        
        mtext("Theisen rainfall (in)", side=1, line=1, cex=cex.lab, at=NA, outer=TRUE)
        mtext("Proportion of total loading", side=2, line=2, cex=cex.lab, at=NA, outer=TRUE)
    }
@


<<proportion>>=
    q_90 = list()
    
    for(target in c("stot_tot", "ptot_tot"))
    {
        output = paste(target, "_major", sep="")
        q=vector()
        for(stream_name in streams){
            stream = get(stream_name)
            stream[output] <- with(stream, ifelse(get(target)>quantile(get(target), 0.9, na.rm=TRUE),1,0))
            stream$major <- with(stream, ifelse(get(target)>quantile(get(target), 0.9, na.rm=TRUE),1,0))
            proportion = sum(stream[stream[output]==1,target], na.rm=TRUE)/sum(stream[,target], na.rm=T)
            q = c(q, proportion)
            assign(stream_name, stream) }
            
        names(q) = streams
        q_90[[target]] = q
    }
@



\section{Goal}
Stream health is threatened by high sediment and phosphorus loads, which are carried into the streams by runoff from the surrounding landscape. It has been shown previously\cite{Danz:2010} that the phosphorus and sediment loads in Wisconsin are not evenly distributed in time - rather, most of the annual loading arrives during two pulses: one in early spring, associated with the melting of the winter snowpack, and the other in midsummer, at the same time as the most intense summer thunderstorms.\\

In this study, we define loading ``events" that can span multiple days of continuous runoff. Our goal is to then characterize the events that produce the greatest loading, in order to inform management practices that aim to improve stream health by reducing sediment and phosphorus loads. Our ultimate goal is a mathematical model of stream loading based on some easily-interpretable covariates. Ideally, we will arrive at a global model for all the sites in the study. The alternative are a collection of local models that seem to describe only the specific sites at which they are calibrated.\\

\section{Data}
\paragraph{Description}
The data in this report comes from eight Wisconsin streams that were monitored (with some gaps in data collection) between 1989 and 2009. The streams and the period during which each was monitored are in Table \ref{table:dates}, except that the phosphorus loading was not measured at Brewery Creek from October 1999 onward.\\

\begin{table}[h]
\begin{center}
\begin{tabular}{r c l}
        \textbf{Stream}  & \textbf{Events} & \textbf{Years}\\
        Eagle & 429 & 1991-1994, 2003-2007\\
        Joos Valley & 473 & 1990-1994, 2002-2007\\
        Otter & 424 & 1990-1997, 2000-2002\\
        Brewery & 670 & 1985, 1990-1998, 2000-2001\\
        Garfoot & 527 & 1985, 1990-1993, 1995-1998\\
        Kuenster & 218 & 1992-1995\\
        Rattlesnake & 170 & 1991-1994\\
        Bower & 373 & 1990-1994, 2006-2009\\
    \end{tabular}
    \label{table:dates}
\end{center}
\end{table}

Each entry in our data set represents one loading event. Events are defined based on the hydrograph - an event begins when the flow rises from a base level toward a peak, and ends when the flow falls back to its new base level. A computer program called Rainmaker was used to separate the total stream flow into base flow and storm flow components. The hydrograph separation is done by analyzing the beginning and ending base flows and the peak storm flow for each event. The storm flow input that drives each event can come from rainfall, from melting snow, or from some combination of the two.

Two kinds of load are measured for each event - the sediment load and the phosphorus load. The load from each event can be divided into two components: the base flow component and the storm flow component. The two components refer, respectively, to the load carried by the stream's base flow and that carried by the additional storm flow pulse. Rainmaker separates the two components based on the hydrograph.\\

Not all of the data can be collected for each event. For instance, rainfall is measured only when the ground is free of snow, because snow interferes with the rain gauges. And the amount of snowmelt is estimated by multiplying the snow's water content by the change in snow depth during a warm snap, which is inaccurate when additional snow falls during the event. Broadly, there is one set of measurements that are made during rainfall-driven events and a different set of measurements that are made during snowmelt-driven events. Because of this, the two types of event are modeled separately. Furthermore, compared to the data about events that are rainfall-driven, the data about events that are snowmelt-driven is of lower quality. That's because: the accuracy of the stream gauge is reduced by ice on the stream, the winter rainfall, snow depth, and water content are not measured locally (snow data tends (or is it always?) to come from the nearest large airport.) It would be surprising if the accuracy of models for snowmelt-driven loading were comparable to that of models for rainfall-driven loading.\\

All else being equal, a stream that drains a larger area should have a greater flow, and should carry a greater load of sediment and phosphorus. For this reason, the sediment and phosphorus loads were divided by the drainage area to get the sediment and phosphorus yields. The yields will be the output from our models.\\

We augmented the data with some antecedent values that we thought could possibly affect the loadings produced during an event. These were the base flow one day before the event, the two-day antecedent mean temperature, the maximum temperature over the two days before the event, and the range between the two-day antecedent max and min temperatures.\\

Some of the data were measured at a gauge station on each stream - these were the stream gauge, local rainfall (including intensity and duration), and the concentrations of sediment and phosphorus (the concentrations were multiplied by the stream flow to get the loadings.) Other data such as rainfall, snowfall, snow depth, snow water content, and air temperature were measured by the National Weather Service (NWS) at a permanent weather station. We downloaded these data from a database maintained by the NWS. Finally we have some metadata that describes our data at the watershed level: the drainage area, the average stream slope, and the land use composition.\\

Some of the variables in the analysis were generated from the measurements rather than being measured directly. For instance, the sediment yield (tons per square mile) and phospohrus yield (pounds per square mile) were calculated by dividing each event's sediment and phosphorus loads (tons and pounds, respectively) by the area of the watershed in which the event occured (areas are measured in square miles). the yield was used instead of the load because yields are comparable between watersheds of different sizes. Similarly, in order to compare differently-sized streams, each event's antecedent baseflow was transformed into an antecedent baseflow quantile. This quantile is the proportion of the events in the same stream with a smaller antecedent baseflow.


\paragraph{Exploratory Analysis}
The first task was to determine how loads are distributed between snowmelt-driven and rainfall-driven events. The total loads from each kind of event are tabulated in Table \ref{tab:rainorsnow}. Figure \ref{bars} presents the same information as the tables, while Figure \ref{boxplots} also compares the load from indivudual snowmelt- and rainfall-driven events. In general, more of the load of both phosphorus and sediment is from rainfall-driven events, but at Garfoot and Kuenster more of the both kinds of load came from snowmelt-driven events. At all sites except Garfoot and Kuenster, snowmelt-driven events contributed a larger proportion of phosphorus loading than of sediment loading (and at Garfoot and Kuenster, difference between the proportions was small.) At most sites the difference between the proportion of sediment load produced by snowmelt-driven events and the proportion of phosphorus load produced by snowmelt-driven events was less than ten percentage points, but at Bower the difference was about 34 percentage points. This suggests that melting snow carries proportionally more phosphorus than does rainfall-runoff, which might be the case if the the phosphorus is from animal poop that accumulates on fallen snow, while the sediment comes from dirt that is mainly trapped under the snowpack.\\

\subparagraph{Rainfall-driven events}
We investigated dividing the snow-free seasons into early and late subseasons, separating the two on May 15th of each year. If vegetation serves to hold the soil together, and to increase both evapotranspiration and infiltration, then erosion may be more common early in the spring before most of the summer's vegetation appears. If so, the relationship between rainfall and the stream's loading might change during the summer.\\

The investigation was done by making linear models to describe the sediment and phosphorus loading during the two subseasons and comparing them to a single model fit to the entire snow-free period. Because the split makes the model more flexible, it will certainly improve the model's fit - the question is whether that improvement is enough to justify making the model more complex. At all four streams, the model improvement was statistically significant but too small to matter (the split models explained about 1\%-2\% more of the loads). We will not use the split in the rest of the analysis.\\


<<combined_table, include=TRUE, results=tex>>=
    library(xtable)
    print(xtable(cbind(stot_tot_percentages, ptot_tot_percentages), caption="Proportion of total loading contributed by each type of event", label="ab:rainorsnow", align=c('l', 'c', 'c', 'c', 'c')), caption.placement="bottom", hline.after=0, add.to.row=list(pos=list(-1), command=" & \\multicolumn{2}{c}{Sediment} & \\multicolumn{2}{c}{Phosphorus} \\\\\n") )
@

\subparagraph{Snowmelt-driven events}
Since sediment and phosphorus are carried into streams by runoff, it makes intuitive sense that the amount of loading during an event should depend on the amount of runoff during that event. In the case of rainfall-driven loading events, it is straightforward to use rain gauges to measure the amount of water entering the stream system. In the case of snowmelt-driven loading events, though, it is not easy to measure how much water melts out of the snowpack, especially when there is also additional snow falling at the same time. There is a subset of events for which we are able to estimate the amount of melting water: Those are the events when we have a measurement of the snow's water content and of the snow depth both before and after the event, and no additional snow falls during the event.\\

\subparagraph{Major events}
Over the course of the monitoring period, the majority of the total load (both of sediment and of phosphorus) was carried during just a few major events. Just 10\% of the events carried between \Sexpr{round( 100*min(q_90$stot_tot), 1 )}\% (at \Sexpr{stream_names[[names(which.min(q_90$stot_tot))]]}) and \Sexpr{round( 100*max(q_90$stot_tot), 1 )}\% (at \Sexpr{stream_names[[names(which.max(q_90$stot_tot))]]}) of the total sediment load; the same events produced between \Sexpr{round( 100*min(q_90$ptot_tot), 1 )}\% (at \Sexpr{stream_names[[names(which.min(q_90$ptot_tot))]]}) and \Sexpr{round( 100*max(q_90$ptot_tot), 1 )}\% (at \Sexpr{stream_names[[names(which.max(q_90$ptot_tot))]]}) of the total phosphorus load.\\

<<major_table, include=TRUE, results=tex>>=
    library(xtable)
    names(q_90) = c("sediment", "phosphorus")
    n = sapply(streams, function(x) {sum(get(x)[['major']], na.rm=TRUE)})
    s = sapply(q_90$sediment, function(x) {paste(round(x*100, 0), "%", sep="")})
    p = sapply(q_90$phosphorus, function(x) {paste(round(x*100, 0), "%", sep="")})
    print(xtable(cbind(count=n,sediment=s,phosphorus=p), caption="Percentage of loading that comes from the biggest ten percent of events at each site.", label="tab:majorload", align=c('l', 'c', 'c', 'c')), caption.placement="bottom", hline.after=0 )
@


<<breakdown_major_events_rain_or_snow>>=
    prp_major = proportions(streams, "stot_tot_major", col.names=c("snowmelt-driven", "rainfall-driven"))
    prp_all = proportions(streams, "event", col.names=c("snowmelt-driven", "rainfall-driven"))
@


\begin{table}[h] \small
    \begin{center}
    \begin{tabular}{lrl}
    \textbf{Sediment} & $R^2$ & Model terms \\
    \hline
<<sediment_selection_table, include=TRUE, results=tex>>=
R2_table(es)
R2_table(js)
R2_table(os)
R2_table(bs)
R2_table(gs)
R2_table(ks)
R2_table(rs)
R2_table(bows)
R2_table(as)
@
    \end{tabular}
    \caption{Results of variable selection for a model of sediment yield (tons/$\text{mi}^2$) from rainfall-driven events\label{sed_r_square_nosnow}}
    \end{center}
\end{table}

\begin{table}[h] \small
    \begin{center}
    \begin{tabular}{lrl}
    \textbf{Phosphorus} & $R^2$ & Model terms \\
    \hline
<<phosphorus_selection_table, include=TRUE, results=tex>>=
R2_table(ep)
R2_table(jp)
R2_table(op)
R2_table(bp)
R2_table(gp)
R2_table(kp)
R2_table(rp)
R2_table(bowp)
R2_table(ap)
@
    \end{tabular}
    \caption{Results of variable selection for a model of phosphorus yield (pounds/$\text{mi}^2$) from rainfall-driven events\label{phos_r_square_nosnow}}
    \end{center}
\end{table}


\begin{table}[h] \small
    \begin{center}
    \begin{tabular}{lrl}
    \textbf{Sediment} & $R^2$ & Model terms \\
    \hline
<<sediment_selection_table-snow, include=TRUE, results=tex>>=
R2_table(es_snow2)
R2_table(js_snow2)
R2_table(os_snow2)
R2_table(bs_snow2)
R2_table(gs_snow2)
R2_table(ks_snow2)
R2_table(rs_snow2)
R2_table(bows_snow2)
R2_table(as_snow2)
@
    \end{tabular}
    \caption{Results of variable selection for a model of sediment yield (tons/$\text{mi}^2$) from snowmelt-driven events.\label{sed_r_square_snow}}
    \end{center}
\end{table}



\begin{table}[h] \small
    \begin{center}
    \begin{tabular}{lrl}
    \textbf{Phosphorus} & $R^2$ & Model terms \\
    \hline
<<phosphorus_selection_table-snow, include=TRUE, results=tex>>=
R2_table(ep_snow2)
R2_table(jp_snow2)
R2_table(op_snow2)
R2_table(bp_snow2)
R2_table(gp_snow2)
R2_table(kp_snow2)
R2_table(rp_snow2)
R2_table(bowp_snow2)
R2_table(ap_snow2)
@
    \end{tabular}
    \caption{Results of variable selection for a model of phosphorus yield (pounds/$\text{mi}^2$) from snowmelt-driven events.\label{phos_r_square_snow}}
    \end{center}
\end{table}


\section{Analysis}

\subsection{Variable selection}
In order to make a model of the load carried by the stream, we need to select the predictor variables that have explanatory power. We used stepwise regression with the Bayesian Information Criterion (BIC) to screen the potential predictor variables. We begin the selection with an intercept-only model, and at each step we add or remove one variable. The variable that is added or removed is the one whose addition or removal will do the most to reduce the BIC. If no such variable is found, then selection is considered complete.\\

\paragraph{Rainfall-driven events}


The variables that were used in the variable selection step as potential predictors of the runoff (sediment or phosphorus) from rainfall-driven events are:\\

\begin{itemize}
    \item\verb!num_events! is the number of stormflow events that occurred between the hydrograph's initial rise from baseflow and its eventual settling to a new baseflow.
    \item \verb!p5_max! is the maximum 5-minute rainfall intensity, and the other \verb!pXX_max! variables are similar measurements over a period of \verb!XX! minutes.
    \item \verb!ei! is the erosivity index.
    \item \verb!duration! is the length of the hydrograph event in days.
    \item \verb!ap_1day! is the amount of rainfall in the day preceding the rise in the hydrograph. Other variables like \verb!ap_Xday! are similar but over different time   ranges.\\
    \item \verb!tmax!, \verb!tmin!, and \verb!tmean! are the maximum, minimum, and mean temperatures during the hydrograph event.
    \item \verb!antecedent_qbase_quantile! is the proportion of days during the study period when the baseflow at the site was lower than when this hydrograph event began.
    \item \verb!nws_prec! is the rainfall measured by the nearest NWS gauge station.
    \item \verb!melt_snow! is the amount of snowmelt during the event (estimated from change in snow depth, and the snow water equivalent).
    \item \verb!cos_julian! and \verb!sin_julian! calculated by \verb!cos(julian*2*pi/365 - 0.35)! and \verb!sin(julian*2*pi/365 - 0.35)!, respectively.
    \item \verb!antecedent_tmean! \verb!antecedent_tmin!, and \verb!antecedent_tmax! are the mean, maximum, and minimum air temperatures over the two days preceding the hydrograph event.
\end{itemize}

In addition to those variables, which were used in models for each individual watershed, the following were also included in the variable selection for a model that describes all the watersheds simultaneously:\\

\begin{itemize}
    \item \verb!slope! is the elevation loss per river mile upstream of the gauge station (note: I've forgotten the distance upstream that is used for the stream slope calculation - Wesley). This is a watershed-level variable - it can be used to compare data between watersheds but not multiple observations within the same watershed.
    \item \verb!area! is the watershed area drained by the stream in question. Like \verb!slope!, it is a watershed-level measurement and so is only relevant as a predictor in the model that describes the combined data.
\end{itemize}

The predictors that survived the screening at each stream are listed in Table \ref{nosnow_predictor_list}. The variables are listed in the order of their importance to the model.\\

\begin{table}[h!]\small
    \begin{center}
    \begin{tabular}{ll}
        \textbf{Solids} & \\
        \hspace{5mm} Eagle: & \Sexpr{ sanipaste2(es$ranked, collapse=", ") }\\
        \hspace{5mm} Joos: & \Sexpr{ sanipaste2(js$ranked, collapse=", ") }\\
        \hspace{5mm} Otter: & \Sexpr{ sanipaste2(os$ranked, collapse=", ") }\\
        \hspace{5mm} Brewery: & \Sexpr{ sanipaste2(bs$ranked, collapse=", ") }\\
        \hspace{5mm} Garfoot: & \Sexpr{ sanipaste2(gs$ranked, collapse=", ") }\\
        \hspace{5mm} Kuenster: & \Sexpr{ sanipaste2(ks$ranked, collapse=", ") }\\
        \hspace{5mm} Rattlesnake: & \Sexpr{ sanipaste2(rs$ranked, collapse=", ") } \\
        \hspace{5mm} Bower: & \Sexpr{ sanipaste2(bows$ranked, collapse=", ") }\\
        \hspace{5mm} Aggregate: & \Sexpr{ sanipaste2(as$ranked, collapse=", ") }
    \vspace{2mm}\\
        \textbf{Phosphorus} & \\
        \hspace{5mm} Eagle: & \Sexpr{ sanipaste2(ep$ranked, collapse=", ") }\\
        \hspace{5mm} Joos: & \Sexpr{ sanipaste2(jp$ranked, collapse=", ") }\\
        \hspace{5mm} Otter: & \Sexpr{ sanipaste2(op$ranked, collapse=", ") }\\
        \hspace{5mm} Brewery: & \Sexpr{ sanipaste2(bp$ranked, collapse=", ") }\\
        \hspace{5mm} Garfoot: & \Sexpr{ sanipaste2(gp$ranked, collapse=", ") }\\
        \hspace{5mm} Kuenster: & \Sexpr{ sanipaste2(kp$ranked, collapse=", ") }\\
        \hspace{5mm} Rattlenake: & \Sexpr{ sanipaste2(rp$ranked, collapse=", ") }\\
        \hspace{5mm} Bower: & \Sexpr{ sanipaste2(bowp$ranked, collapse=", ") }\\
        \hspace{5mm} Aggregate: & \Sexpr{ sanipaste2(ap$ranked, collapse=", ") }\\
    \end{tabular}
    \caption{The most important variables in the models for rainfall-driven loading. The variables are ordered by their importance to the model of the yield. \label{nosnow_predictor_list}}
    \end{center}
\end{table}

In each case, the two most important predictors are the theisen rainfall and the antecedent baseflow. Using just those two predictors results in an $R^2$ greater than 0.7 in most models (see Tables \ref{sed_r_square_nosnow} and \ref{phos_r_square_nosnow}.) Since the antecedent baseflow is considered an indicator of how much water is in the watershed before each event, we conclude that the amount of sediment and phosphorus washed into a stream by each event is mainly a function of the quantity of water moving through the system. At Brewery Creek, the intensity of rainfall is a more important predictor than the total quantity of rain.\\

The performance of the global (aggregate) model is quite good: with just two predictors (sediment: \Sexpr{sanipaste2(as$ranked[1:2], collapse=", ")}, phosphorus: \Sexpr{sanipaste2(ap$ranked[1:2], collapse=", ")}) the $\text{R}^2$ is \Sexpr{round(as$R2[2], 2)} and \Sexpr{round(ap$R2[2], 2)}, respectively. In the case of sediment, the next-most-important predictor is the stream slope. Including it in the model pushes the $\text{R}^2$ to \Sexpr{round(ap$R2[3], 2)}.\\

\paragraph{Snowmelt-driven events} 

The following are the varaibles from which we selected the models for each individual watershed's runoff from snowmelt-driven events:\\

\begin{itemize}
    \item \verb!num_days! is defined for its role in the snowmelt-driven events.
    \item \verb!tmin!, \verb!tmax!, and \verb!tmean! are defined for their role in the snowmelt-driven events.
    \item \verb!nws_snow! I am not certain exactly what this is - Wesley.
    \item \verb!nws_prec! is defined for its role in the snowmelt-driven events.
    \item \verb!melt_water! is an estimate of the amount of snowmelt, calculated from the change in snow depth and the estimated water content of the snowpack. Units are inches (like inches of rain).
    \item \verb!total_water! is the sum of the measured rainfall and the estimated snowmelt. Units are inches (like inches of rain).
    \item \verb!antecedent_tmean!, \verb!antecedent_tmin!, and \verb!antecedent_tmax! are defined for their role in the snowmelt-driven events.
    \item \verb!antecedent_qbase_quantile! is defined for its role in the snowmelt-driven events.
    \item \verb!cos_julian! and \verb!sin_julian! are defined for their role in the snowmelt-driven events.
\end{itemize}

In addition to all of those variables, the following were also used for selecting a model to describe the snowmelt-driven runoff from all watersheds simultaneously:

\begin{itemize}
    \item \verb!slope! and \verb!area! are watershed-level variables and are defined in the section about rainfall-driven runoff.
\end{itemize}
 
 We had less success modeling the loading produced by the snowmelt-driven events. The predictors that survived the screening process were different from stream to stream and those variables that did survive at most sites weren't always selected in the same order (like they were for the rainfall-driven events). What's more, the models for snowmelt-driven events were less accurate than for rainfall-driven events, ranging in $R^2$ from 0.24 to 0.53, with most in the 0.45 range.\\

At most sites, the most important predictor was a temperature measurement, either the maximum or the mean temperature during the loading event. The antecedent baseflow also appears to be important at most sites. It seems likely that, as in the case of rainfall-driven events, the loading is driven by the quantity of water that moves through the watershed during the event.\\

\begin{table}[h!]\small
    \begin{center}
    \begin{tabular}{ll}
        \textbf{Solids} & \\
        \hspace{5mm} Eagle: & \Sexpr{ sanipaste2(es_snow2$ranked, collapse=", ") }\\
        \hspace{5mm} Joos: & \Sexpr{ sanipaste2(js_snow2$ranked, collapse=", ") }\\
        \hspace{5mm} Otter: & \Sexpr{ sanipaste2(os_snow2$ranked, collapse=", ") }\\
        \hspace{5mm} Brewery: & \Sexpr{ sanipaste2(bs_snow2$ranked, collapse=", ") }\\
        \hspace{5mm} Garfoot: & \Sexpr{ sanipaste2(gs_snow2$ranked, collapse=", ") }\\
        \hspace{5mm} Kuenster: & \Sexpr{ sanipaste2(ks_snow2$ranked, collapse=", ") }\\
        \hspace{5mm} Rattlesnake: & \Sexpr{ sanipaste2(rs_snow2$ranked, collapse=", ") } \\
        \hspace{5mm} Bower: & \Sexpr{ sanipaste2(bows_snow2$ranked, collapse=", ") }\\
        \hspace{5mm} Aggregate: & \Sexpr{ sanipaste2(as_snow2$ranked, collapse=", ") }
    \vspace{2mm}\\
        \textbf{Phosphorus} & \\
        \hspace{5mm} Eagle: & \Sexpr{ sanipaste2(ep_snow2$ranked, collapse=", ") }\\
        \hspace{5mm} Joos: & \Sexpr{ sanipaste2(jp_snow2$ranked, collapse=", ") }\\
        \hspace{5mm} Otter: & \Sexpr{ sanipaste2(op_snow2$ranked, collapse=", ") }\\
        \hspace{5mm} Brewery: & \Sexpr{ sanipaste2(bp_snow2$ranked, collapse=", ") }\\
        \hspace{5mm} Garfoot: & \Sexpr{ sanipaste2(gp_snow2$ranked, collapse=", ") }\\
        \hspace{5mm} Kuenster: & \Sexpr{ sanipaste2(kp_snow2$ranked, collapse=", ") }\\
        \hspace{5mm} Rattlesnake: & \Sexpr{ sanipaste2(rp_snow2$ranked, collapse=", ") }\\
        \hspace{5mm} Bower: & \Sexpr{ sanipaste2(bowp_snow2$ranked, collapse=", ") }\\
        \hspace{5mm} Aggregate: & \Sexpr{ sanipaste2(ap_snow2$ranked, collapse=", ") }\\
    \end{tabular}
    \caption{The most important variables in the models for snowmelt-driven loading. The variables are ordered by their importance to the model of the yield. \label{snow_predictor_list}}
    \end{center}
\end{table}


<<aggregate_sediment_model, include=TRUE, results=tex>>=
    print(xtable(lm(log_stot_yield~theisen+antecedent_qbase_quantile+slope, data=aggregate_nosnow), floating=FALSE, caption="Summary table for of model for log(sediment yield) during the rainfall period."))
@


<<aggregate_phosphorus_model, include=TRUE, results=tex>>=
    print(xtable(lm(log_ptot_yield~theisen+antecedent_qbase_quantile, data=aggregate_nosnow), floating=FALSE, caption="Summary table for of model for log(phosphorus yield) during the rainfall period."))
@


<<aggregate_sediment_model_snow, include=TRUE, results=tex>>=
    print(xtable(lm(log_stot_yield~tmax+antecedent_qbase_quantile+num_days+nws_prec, data=aggregate_snow), floating=FALSE, caption="Summary table for of model for log(sediment yield) during the snowmelt period."))
@


<<aggregate_phosphorus_model_snow, include=TRUE, results=tex>>=
    print(xtable(lm(log_ptot_yield~tmax+antecedent_qbase_quantile+num_days+nws_prec, data=aggregate_snow), floating=FALSE, caption="Summary table for of model for log(phosphorus yield) during the snowmelt period."))
@


\section{Conclusions}
We have an accurate global model that describes the loading that will result from a rainstorm, based just on the base flow before the storm and on the amount of rain that falls during the storm. Antecedent base flow is a measurement of how much water is in the watershed before a storm and any new water comes as rainfall, so it seems that the sediment and phosphorus loads are driven mainly by the quantity of water moving through the watershed. The stream slope also seems to be important; that could be because steeper slopes give surface water less time to infiltrate and therefore increase the intensity of a rainfall event.\\

We have not yet found an accurate way to model the amount of load during a snowmelt-driven event but we have seen that the air temperature (which drives snowmelt), the antecedent base flow, and the amount of additional precipitation are important predictors for those events.\\

Most of the annual loading seems to be produced by a few major events. If the goal is to reduce the impact of sediment and phosphorus loading on stream health, then something must be done to mitigate the impact of those major events. Figures \ref{cdf-s} and \ref{cdf-p} make it look like the majority of the ranfall-driven loading comes from storms that drop at least two inches of rain. Mitigating the effect of large storms will probably require slowing the water's movement through the watershed - for instance, by impounding runoff before it can flow into the creeks. A further analysis should look at the frequency of big storms in order to get an idea of how quickly impounded water must be dealt with in order to be ready for the next event.\\


\begin{figure}
    \begin{center}
<<figure2, fig=TRUE, include=TRUE, fig.width=12, fig.height=15>>=
    cumulative(lwd=2, las=1, line.xaxis=1.2)
@
    \end{center}
    \caption{Proportion of the total load contributed by rainfall events up to the size shown. Snowmelt-driven events are excluded.\label{cdf}}
\end{figure}


\begin{figure}
    \begin{center}
<<figure4, fig=TRUE, include=TRUE, fig.width=12, fig.height=15>>=
    bubble("stot_tot", scale=0.15, bg="grey65", fg="black", line.xaxis=1.2)
@
    \end{center}
    \caption{Antecedent base flow is the horizontal axis; theisen rainfall is the vertical axis. Each dot represents one event. The size of the dot shows the total sediment load (in tons) contributed by that event. \label{sed_bubbles}}
\end{figure}


\begin{figure}
    \begin{center}
<<figure5, fig=TRUE, include=TRUE, fig.width=12, fig.height=15>>=
    bubble("ptot_tot", scale=0.15, bg="grey65", fg="black", line.xaxis=1.2)
@
    \end{center}
    \caption{Antecedent base flow is the horizontal axis; theisen rainfall is the vertical axis. Each dot represents one event. The size of the dot shows the total phosphorus load (in pounds) contributed by that event. \label{phos_bubbles}}
\end{figure}


<<guide, results=tex, eval=FALSE>>=
    stream = "eagle"
    stream = get(stream)
    
    snow = stream[stream$snow==TRUE,]
    guide(stot_tot~nws_prec + total_water + nws_snow + melt_snow + tmean + tmax + tmin + sweq + julian + sin_julian + cos_julian,
          data=snow, sweave=T, cv_gain=0)
    
    rain = stream[stream$snow==FALSE,]
    guide(stot_tot~nws_prec+event_type+ap_1day+ap_2day+ap_3day+total_water+theisen+sweq+julian+sin_julian+cos_julian+tmean+tmax+tmin,
          data=rain, sweave=T, cv_gain=0)
@

\bibliographystyle{plain}
\bibliography{../references/loadings}

\end{document}
