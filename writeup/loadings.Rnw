\documentclass[10pt]{article}
\usepackage{geometry}                % See geometry.pdf to learn the layout options. There are lots.
\geometry{letterpaper}                   % ... or a4paper or a5paper or ... 
%\geometry{landscape}                % Activate for for rotated page geometry
\usepackage[parfill]{parskip}    % Activate to begin paragraphs with an empty line rather than an indent
\usepackage[cm]{fullpage}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage[margin=20pt, font=small, labelfont=sc, labelsep=endash]{caption}
\usepackage{subfig}
\usepackage{multirow}
%\usepackage{pstricks, pst-node,pst-tree}


\title{Analysis of loadings}
\author{Wesley Brooks}
\date{}                                           % Activate to display a given date or no date

\begin{document}
\setkeys{Gin}{width=0.9\textwidth}    %make figures a bit wider than the Sweave default.
\maketitle

<<label=read_data, echo=FALSE>>=
    #Read data into R and do some basic manipulation to get it into a usable format:
    setwd('c:/Users/wrbrooks/git/loadings/writeup')
    source('c:/Users/wrbrooks/git/loadings/code/guide.r')
    streams = c('eagle', 'joosvalley', 'otter', 'brewery', 'garfoot', 'kuenster', 'rattlesnake', 'bower')
    stream_names = list(eagle='Eagle', joosvalley='Joos', otter='Otter', bower='Bower',
                        brewery='Brewery', garfoot='Garfoot', kuenster='Kuenster', rattlesnake="Rattlesnake")
    outputs = c('sstorm_tot', 'sstorm_max', 'sstorm_avg', 'stot_tot', 'stot_max', 'stot_yield', 'ptot_yield', 
                    'stot_avg', 'pstorm_tot', 'pstorm_max', 'pstorm_avg', 'ptot_tot', 'ptot_max', 'ptot_avg')
    
    #Names of the NWS data files for each creek
    nws_files = list("eagle"=c("eagle/NWS/Winona_91-94_ASCII.txt", "eagle/NWS/Winona_03-07_ASCII.txt"),
                        "joosvalley"=c("eagle/NWS/Winona_91-94_ASCII.txt", "eagle/NWS/Winona_03-07_ASCII.txt"),
                        "otter"=c("otter/NWS/Sheboygan_Otter_raw.txt"),
                        "brewery"=c("brewery/NWS/Madison_SND.txt"),
                        "garfoot"=c("garfoot/NWS data/madison_daily.txt"),
                        "kuenster"=c("Kuenster/NWS data/Guttenberg_raw.txt"),
                        "rattlesnake"=c("Kuenster/NWS data/Guttenberg_raw.txt"),
                        "bower"=c("bower/NWS data/greenbay_raw.txt", "bower/NWS data/greenbaypost_raw.txt"))
    
    #Location of the raw loading data file for each creek
    daily_load_data = list()
    raw_load_files = list("eagle"=c("eagle/eagle_loads.txt"),
                        "joosvalley"=c("joosvalley/joos_loads.txt"),
                        "otter"=c("otter/otter_loads.txt"),
                        "brewery"=c("brewery/brewery_loads.txt"),
                        "garfoot"=c("garfoot/garfoot_loads.txt"),
                        "kuenster"=c("Kuenster/kuenster_loads.txt"),
                        "rattlesnake"=c("Rattlesnake/rattle_loads.txt"),
                        "bower"=c("bower/bower_loads.txt"))
    
    watersheds = read.csv("../data/watersheds.csv", header=T)
    
    #loop through the streams, reading them in one by one
    for(stream_name in streams)
    {
        data_file = paste('../data/', stream_name, '/', stream_name, 'creek.csv', sep='')
        stream = read.csv(data_file, header=T, na.strings=c('NA', 'na')) 
        
        #read the daily flow file, which we use for antecedent moisture contitions
        daily_flow = paste("../data/", stream_name, "/", stream_name, "_q.out", sep="")
        head = strsplit( readLines(daily_flow)[1], "\t" )
        daily_flow = read.table(daily_flow, skip=2, col.names=unlist(head))
        daily_flow$DV_date = with( daily_flow, as.POSIXlt( as.character(DV_date), format="%m/%d/%Y" ) )
        
        #do some basic data transformations:
        stream = within( stream, {
            event_type <- factor(event_type)
            stot_yield <- stot_tot / watersheds$area[watersheds$stream==stream_name]
            ptot_yield <- ptot_tot / watersheds$area[watersheds$stream==stream_name]
            year <- factor(year)
            melt_snow[melt_snow=='N' | melt_snow=='Z' | melt_snow=='U'] <- NA
            melt_snow <- as.numeric(levels(melt_snow)[melt_snow])
            sweq <- as.numeric(sub("%", "e-2", sweq))
            ap_1day <- as.numeric(ap_1day)
            ap_3day <- as.numeric(ap_3day)
            ap_5day <- as.numeric(ap_5day) 
            tmax <- as.numeric(tmax)
            tmin <- as.numeric(tmin)
            tmean <- as.numeric(tmean)
            stream <- as.factor(stream_name)
            start_day <- as.POSIXlt( as.character(start_day), format="%m/%d/%Y" )
            year <- as.numeric(as.character(year))
            water_year <- ifelse(month>=10, year+1, year)
            julian <- start_day$yday + 1
            sin_julian <- sin(julian*2*pi/365)
            cos_julian <- cos(julian*2*pi/365)
            for(output in outputs)
                assign( paste('log_', output, sep=""), log10(get(output)+0.01) )
            m <- as.factor(ifelse(is.na(m),0,ifelse(m=='M','M',0)))
            event <- rep(1, length(m))
            area <- watersheds$area[watersheds$stream==stream_name]
            slope <- watersheds$slope[watersheds$stream==stream_name]
            urb <- watersheds$urb[watersheds$stream==stream_name]
            ag <- watersheds$ag[watersheds$stream==stream_name]
            forest <- watersheds$forest[watersheds$stream==stream_name]
            water <- watersheds$water[watersheds$stream==stream_name]
            wetland <- watersheds$wetland[watersheds$stream==stream_name]
            other <- watersheds$other[watersheds$stream==stream_name]
            } )
    
        #Get the raw daily loads at each site
        daily_load = data.frame()
        for( raw_load_file in get(stream_name, pos=raw_load_files)) {
            raw_path = paste("../data/", raw_load_file, sep="")
            daily_load = rbind(daily_load, read.table(raw_path, na.strings=c("", "99999", "-1.23E+25"), header=TRUE)) }
        daily_load$date = with( daily_load, as.POSIXlt( as.character(date), format="%m/%d/%Y" ) )
        daily_load_data[[stream_name]] = daily_load
        
        #Find the base flow that immediately preceded each event
        antecedent_qbase = rep(NA, length(stream$start_day))
        for( i in 1:length(antecedent_qbase) ) {
            #get the date just prior to row i (subtraction is in units of seconds)
            unmatched = identical(which( daily_flow$DV_date == stream$start_day[i]-86400 ), integer(0))
            antecedent_qbase[i] = ifelse(unmatched, NA, daily_flow[which( daily_flow$DV_date == stream$start_day[i]-86400 ), 'QGW_fixed']) }
        stream$antecedent_qbase = antecedent_qbase
    
        #Find the average air temperature in the days before the event:
        #first, read the raw air temperature data
        nws = data.frame()
        for( nws_file in get(stream_name, pos=nws_files))
        {
            nws_path = paste("../data/", nws_file, sep="")
            nws = rbind(nws, read.csv(nws_path, na.strings=c("", "99999", "-1.23E+25", "null"), header=TRUE))
        }
        nws$date = with(nws, ISOdate(year=year, month=month, day=day))
    
        #Now find the antecedent air temperature for each event
        #We will compute the mean, min, and range of air temps before this event began.
        antecedent_tmean = rep(NA, length(stream$start_day))
        antecedent_trange = rep(NA, length(stream$start_day))
        antecedent_tmax = rep(NA, length(stream$start_day))
        period = 2 #how far back in days to do the averaging
        for( i in 1:length(antecedent_tmean) )
        {
            to_average = which(nws$date < stream$start_day[i] & nws$date >= stream$start_day[i] - period*86400)
            antecedent_tmean[i] = mean(nws$Tmean[to_average], na.rm=TRUE)
            antecedent_tmax[i] = max(nws$Tmean[to_average], na.rm=TRUE) 
            antecedent_trange[i] = diff(range(nws$Tmean[to_average], na.rm=TRUE))
        }
        stream$antecedent_tmean = antecedent_tmean
        stream$antecedent_tmax = ifelse(antecedent_tmax>-Inf, antecedent_tmax, NA)
        stream$antecedent_trange = ifelse(antecedent_trange>-Inf, antecedent_trange, NA)
    
        #Now add this stream's data to the frame.
        assign(stream_name, stream)
        assign(paste(stream_name, "_flow", sep=""), daily_flow)
    }
    
    #Now mark the class of each event (1:snowmelt-driven, 2:pre-vegetation, 3:post-vegetation)
    #We will gather all the data into one frame:
    aggregate = data.frame()
    
    #loop through the stream sites:
    for(stream_name in streams)
    {
    	stream = get(stream_name)
    
    	#Decide which events are snowmelt-driven:         
    	class = vector()
    	prev_class = 0
    	num_events = dim(stream)[1]
                    
    	#loop through the events                        
    	for(row in 1:num_events)
        {
    		#first look for the beginning of each year's snowmelt events
    		if(stream$m[row]=='M')
            {
    			class = c(class, 1)
    			prev_class = 1
            }
    		else if(prev_class==1 & (stream$month[row]>=10 | stream$julian[row]<=135))
            {
    			class = c(class, 1)
    			prev_class = 1
            }
    		else
            {
    			class = c(class, 3)
    			prev_class = 3
            }
        }
          
    	prev_class = 0
    	for(row in num_events:1)
        {
    		#now look for the end of the snowmelt events
    		if(stream$m[row]=='M')
            {
    			class[row] = 1
    			prev_class = 1
            }
    		else if(class[row]==3)
            {
    			class[row] = 3
    			prev_class = 3
            }
    		else if(stream$julian[row]<=135 & prev_class!=1)
            {
    			class[row] = 2
    			prev_class = 2
            }
    		else
                class[row] = 1
        }
    
          
    	#save the class identifiers back to the stream's data frame
    	stream$event_class = as.factor(class)
        stream$snow = ifelse(stream$event_class==1,TRUE, FALSE)
    	assign(stream_name, stream)
        aggregate = rbind(aggregate, stream)
    }
@


<<label=bubble_plots, echo=False, include=False>>=
    #The "_nosnow" dataframes exclude the snowfall-influenced events.
    num_rows = ceiling(length(streams)/2)
    layout(matrix(1:(2*num_rows), num_rows, 2))
    for(stream_name in streams)
    {
        stream = get(stream_name)
        assign( paste(stream_name, "_nosnow", sep=""), stream[stream$snow==FALSE,] )
        assign( paste(stream_name, "_snow", sep=""), stream[stream$snow==TRUE,] )
    
        #Produce the bubble plots
        symbols(stream[stream$snow==FALSE,]$antecedent_qbase,
                stream[stream$snow==FALSE,]$theisen,
                circles=sqrt( stream[stream$snow==FALSE,]$sstorm_tot/pi ),
                inches=0.25, fg="white", bg="red", bty='n',
                xlim=range(stream[!is.na(stream$antecedent_qbase) & stream$snow==FALSE,]$antecedent_qbase)*c(0.8,1.2),
                ylim=range(stream[!is.na(stream$theisen),]$theisen)*c(0.8,1.2),
                xlab="Antecedent baseflow",
                ylab="Theisen rainfall") 
        
        mtext(stream_names[[stream_name]], side=3, line=-1, cex=1.2,
              at=sum(range(stream[!is.na(stream$antecedent_qbase) & stream$snow==FALSE,]$antecedent_qbase))/1.7)
    }
@


<<label=function_definitions, echo=False, include=False>>=
    #Import the GAM library
    library(mgcv)
    
    #Backslash-escape special characters.
    sanitize <- function(str)
        gsub('([#$%&~_\\^\\\\{}])', '\\\\\\1', str, perl=TRUE)
    
    
    #Double-backslash-escape special characters.
    sanitize2 <- function(str)
        gsub('([#$%&~_\\^\\\\{}])', '\\\\\\\\\\1', str, perl=TRUE)
    
    
    #Paste together a list of strings, backslash-escaping special characters in each one.
    sanipaste <- function(pastelist, ...)
        paste(sanitize(pastelist), ...)
    
    
    #Paste together a list of strings, double-backslash-escaping special characers in each one.
    sanipaste2 <- function(pastelist, ...)
        paste(sanitize2(pastelist), ...)
    
    
    #Determine what proportion of loadings comes from each event class
    proportions <- function(streams, target, col.names)
    {
        result = matrix( nrow=length(streams), ncol=length(col.names) )
    	for(i in 1:length(streams))
        {
    		stream = get(streams[i])
    		result[i,] = sapply(c(TRUE, FALSE), function(x) sum(stream[stream$snow==x,target], na.rm=T) / sum(stream[,target], na.rm=T))
        }
        result = data.frame(result)
        names(result) = col.names
        row.names(result) = sapply(streams, function(x) get(x=x, pos=stream_names))
    	return(result)
    }
    
    
    #Determine what percentage of loadings comes from each event class
    percentages <- function(streams, target, col.names, decimals=1)
    {
        props = proportions(streams, target, col.names)
        result = matrix( nrow=0, ncol=length(col.names) )
        rows = dim(props)[1]
        for( row in 1:rows )
        {
            result = rbind( result, paste( ifelse(round(props[row,]*100, decimals)%%1 == 0,
                paste(as.character( round(props[row,]*100, 0) ), ".0", sep=""),
                as.character( round(props[row,]*100, decimals) )), "%", sep="" ))
        }
        result=data.frame(result)
        names(result) = names(props)
        row.names(result) = row.names(props)
        return(result)
    }
    
    
    #Extracts the terms in the model formula.
    parse_args <- function(model)
        return(attr(model$model, 'names'))
    
    
    #Compute the model's R**2.
    r2 <- function(model)
    {
        actual = model$residual+model$fitted
        rss = sum(model$residual**2)
        tss = sum((actual-mean(actual))**2)
        return(1 - rss/tss)
    }
    
    
    #Adds variables one-by-one to the model, finding the R^2 at each step.
    r2_step <- function(model, variables, data)
    {
        output = attr(model$model, "names")[1]
        call = paste(output, "~", variables[1], sep="")
        
        r_square = vector()
    
        for(variable in variables[-1]) {
            f = as.formula(call)
            model = lm(formula=f, data=data)
            r_square = c(r_square, r2(model))
            call = paste(call, "+", variable) }
        
        model = update(model, formula=call)
        r_square = c(r_square, r2(model))
        
        return(r_square)
    }
    
    
    #This function uses the BIC to screen variables, returning the 'step' object.
    stepwise_BIC <- function(target, data, sites)
    {
        predictors = c("num_events", "theisen", "p5max", "p10max", "p15max", "p30max", "p60max", 
                       "ei", "duration", "ap_1day", "ap_3day", "ap_5day", "tmax", "tmean", "tmin", 
                       "nws_prec", "nws_snow", "melt_snow", "cos_julian", "sin_julian", "antecedent_qbase", 
                       "antecedent_tmean", "antecedent_tmax", "antecedent_trange", "slope", "area")
        d = data[,c(target, predictors)]
        result = list()
        
        full_model = as.formula( paste(target, "~", paste(predictors, collapse="+")) )
        intercept_only = as.formula( paste(target, "~1") )
        fm1 <- lm(full_model, data=d, x=T)
        
        d = data.frame(cbind(target=fm1$fitted+fm1$residual, fm1$x))
        names(d)[1] = target
        fm2 <- lm(intercept_only, data=d)
        screened = step(fm2, scope=full_model, direction='both', k=log(dim(d)[1]), trace=FALSE)
        
        terms = parse_args(screened)
        target = terms[1]
        predictors = terms[-1]
        formula = as.formula(paste(target, "~", paste(predictors, collapse="+")))
        
        model = lm(formula, data=data, x=T)
        
        #Put the results in a list object
        result$site = sites[[as.character(unique(data$stream)[1])]]
        result$model = model
        result$ranked = names(model$model)[-1] # rank_predictors(model)
        result$R2 = r2_step(model, result$ranked, data)
        return(result)
    }
    
    
    #This function uses the BIC to screen variables, returning the 'step' object.
    stepwise_BIC_gam <- function(target, data, sites)
    {
        predictors = c("num_events", "theisen", "p5max", "p10max", "p15max", "p30max", "p60max", 
                       "ei", "duration", "ap_1day", "ap_3day", "ap_5day", "tmax", "tmean", "tmin", 
                       "nws_prec", "nws_snow", "melt_snow", "cos_julian", "sin_julian", "antecedent_qbase", 
                       "antecedent_tmean", "antecedent_tmax", "antecedent_trange")
        d = data[,c(target, predictors)]
        result = list()
        
        predictors = c(predictors, "antecedent_qbase:slope", "antecedent_qbase:area", "total_water:slope", "total_water:area")
        full_model = as.formula( paste(target, "~", paste(predictors, collapse="+")) )
        intercept_only = as.formula( paste(target, "~1") )
        fm1 <- lm(full_model, data=d, x=T)
        
        d = data.frame(cbind(target=fm1$fitted+fm1$residual, fm1$x))
        names(d)[1] = target
        fm2 <- gam(intercept_only, data=d)
        screened = step(fm2, scope=full_model, direction='both', k=log(dim(d)[1]), trace=FALSE)
        
        terms = parse_args(screened)
        target = terms[1]
        predictors = terms[-1]
        formula = as.formula(paste(target, "~", paste(predictors, collapse="+")))
        
        model = lm(formula, data=data, x=T)
        
        #Put the results in a list object
        result$site = sites[[as.character(unique(data$stream)[1])]]
        result$model = model
        result$ranked = names(model$model)[-1] # rank_predictors(model)
        result$R2 = r2_step(model, result$ranked, data)
        return(result)
    }
    
    
    #Use the BIC to screen the predictors that are available when snow is on the ground.
    stepwise_BIC_snow <- function(target, data, sites)
    {
        predictors = c("num_days", "tmax", "tmean", "tmin", "nws_prec", "nws_snow", 
                       "cos_julian", "sin_julian", "antecedent_qbase", "antecedent_tmean", "antecedent_tmax", "antecedent_trange")
        d = data[,c(target, predictors)]
        result = list()
    
        full_model = as.formula( paste(target, "~", paste(predictors, collapse="+")) )
        intercept_only = as.formula( paste(target, "~1") )
        fm1 <- lm(full_model, data=d, x=T)
        
        d = data.frame(cbind(target=fm1$fitted+fm1$residual, fm1$x))
        names(d)[1] = target
        fm2 <- lm(intercept_only, data=d)
        screened = step(fm2, scope=full_model, direction='both', k=log(dim(d)[1]), trace=FALSE)
        
        terms = parse_args(screened)
        target = terms[1]
        predictors = terms[-1]
        formula = as.formula(paste(target, "~", paste(predictors, collapse="+")))
        
        model = lm(formula, data=data, x=T)
        
        #Put the results in a list object
        result$site = sites[[as.character(unique(data$stream)[1])]]
        result$model = model
        result$ranked = names(model$model)[-1] #rank_predictors(model)
        result$R2 = r2_step(model, result$ranked, data)
        return(result)
    }
    
    
    #Use the BIC to screen the predictors that are available when snow is on the ground.
    stepwise_BIC_snow2 <- function(target, data, sites)
    {
        predictors = c("num_days", "tmax", "tmean", "tmin", "nws_prec", "nws_snow", "total_water", "melt_water", "slope", "area",
                       "cos_julian", "sin_julian", "antecedent_qbase", "antecedent_tmean", "antecedent_tmax", "antecedent_trange")
        d = data[,c(target, predictors)]
        result = list()
    
        predictors = c(predictors, "antecedent_qbase:slope", "antecedent_qbase:area", "total_water:slope", "total_water:area")
        full_model = as.formula( paste(target, "~", paste(predictors, collapse="+")) )
        intercept_only = as.formula( paste(target, "~1") )
        fm1 <- lm(full_model, data=d, x=T)
        
        d = data.frame(cbind(target=fm1$fitted+fm1$residual, fm1$x))
        names(d)[1] = target
        fm2 <- lm(intercept_only, data=d)
        screened = step(fm2, scope=full_model, direction='both', k=log(dim(d)[1]), trace=FALSE)
        
        terms = parse_args(screened)
        target = terms[1]
        predictors = terms[-1]
        formula = as.formula(paste(target, "~", paste(predictors, collapse="+")))
        
        model = lm(formula, data=data, x=T)
        
        #Put the results in a list object
        result$site = sites[[as.character(unique(data$stream)[1])]]
        result$model = model
        result$ranked = names(model$model)[-1] #rank_predictors(model)
        result$R2 = r2_step(model, result$ranked, data)
        return(result)
    }
    
    
    #Function to flag the largest observations of a certain variable.
    major <- function(data, target, q=0.9, strata='')
    {
        #Flag the major events within each level of strata
        if(strata != '') {
            major = rep(0, length(data[,target]))
            
            #Loop through the strata
            for(stratum in unique(data[,strata])) {
                indx = which(data[,strata]==stratum)
                major[indx] = ifelse(data[indx,target] > quantile(data[indx,target], q, na.rm=TRUE), 1, 0) } }
                
        #If no stratification is provided, then just flag the overall major events
        else { major = ifelse(data[,target]>quantile(data[,target], q, na.rm=TRUE), 1, 0) }
        
        #Either way, return the result
        return(major)
    }
    
    
    #Produce a boxplot of the per-event loading, showing rainfall- and snowmelt-driven events separately.
    bplot <- function(formula, data, loc, classes, site, ...)
    {
        boxplot(formula, data=data, bty='n', ylim=yy, cex=0.6, pch=4,
                boxwex=0.4, frame.plot=F, ann=F, names=classes, add=T, at=loc:(loc+1), yaxt='n', ...)
        mtext(site, side=1, line=3, at=(loc+0.5))
        
        mtext( paste(round(100*sum(data[data$snow==1,]$ptot_tot)/sum(data$ptot_tot), 0), "%", sep=""), side=3, line=0, cex=0.7, at=loc )
        mtext( paste(round(100*sum(data[data$snow==0,]$ptot_tot)/sum(data$ptot_tot), 0), "%", sep=""), side=3, line=0, cex=0.7, at=(loc+1) )
        
        mtext(sum(data$snow), side=3, line=1, cex=0.7, at=loc )
        mtext(length(data$snow) - sum(data$snow), side=3, line=1, cex=0.7, at=(loc+1) )
    }
    
    
    #Produce a table that shows how the R**2 grows as new variables are added to the model.
    R2_table <- function(varlist)
    {
        numvars = length(varlist$R2)
        cat(paste("\\multirow{", as.character(numvars+1), "}{*}{", varlist$site, "}", sep=""))
        for(i in 1:numvars)
        {
            cat(paste(" & ", as.character(round(varlist$R2[i], 3)), " & ", sep=""))
            
            for(j in 1:i)
            {
                cat(sanitize(varlist$ranked[j]))
                if(j<i)
                    cat(" + ")
            }
            cat("\\\\ \n")
        }
        cat("\\vspace{2mm}\\\\ \n")
    }
@



<<label=variable_selection_nosnow, echo=False, include=False>>=
    es = stepwise_BIC(target="log_stot_yield", data=eagle_nosnow, sites=stream_names)
    js = stepwise_BIC(target="log_stot_yield", data=joosvalley_nosnow, sites=stream_names)
    os = stepwise_BIC(target="log_stot_yield", data=otter_nosnow, sites=stream_names)
    bs = stepwise_BIC(target="log_stot_yield", data=brewery_nosnow, sites=stream_names)
    gs = stepwise_BIC(target="log_stot_yield", data=garfoot_nosnow, sites=stream_names)
    ks = stepwise_BIC(target="log_stot_yield", data=kuenster_nosnow, sites=stream_names)
    rs = stepwise_BIC(target="log_stot_yield", data=rattlesnake_nosnow, sites=stream_names)
    bows = stepwise_BIC(target="log_stot_yield", data=bower_nosnow, sites=stream_names)
    
    ep = stepwise_BIC(target="log_ptot_yield", data=eagle_nosnow, sites=stream_names)
    jp = stepwise_BIC(target="log_ptot_yield", data=joosvalley_nosnow, sites=stream_names)
    op = stepwise_BIC(target="log_ptot_yield", data=otter_nosnow, sites=stream_names)
    bp = stepwise_BIC(target="log_ptot_yield", data=brewery_nosnow, sites=stream_names)
    gp = stepwise_BIC(target="log_ptot_yield", data=garfoot_nosnow, sites=stream_names)
    kp = stepwise_BIC(target="log_ptot_yield", data=kuenster_nosnow, sites=stream_names)
    rp = stepwise_BIC(target="log_ptot_yield", data=rattlesnake_nosnow, sites=stream_names)
    bowp = stepwise_BIC(target="log_ptot_yield", data=bower_nosnow, sites=stream_names)
@

<<label=variable_selection_snow, include=False, echo=False>>=
    es_snow = stepwise_BIC_snow(target="log_stot_yield", data=eagle_snow, sites=stream_names)
    js_snow = stepwise_BIC_snow(target="log_stot_yield", data=joosvalley_snow, sites=stream_names)
    os_snow = stepwise_BIC_snow(target="log_stot_yield", data=otter_snow, sites=stream_names)
    bs_snow = stepwise_BIC_snow(target="log_stot_yield", data=brewery_snow, sites=stream_names)
    gs_snow = stepwise_BIC_snow(target="log_stot_yield", data=garfoot_snow, sites=stream_names)
    ks_snow = stepwise_BIC_snow(target="log_stot_yield", data=kuenster_snow, sites=stream_names)
    rs_snow = stepwise_BIC_snow(target="log_stot_yield", data=rattlesnake_snow, sites=stream_names)
    bows_snow = stepwise_BIC_snow(target="log_stot_yield", data=bower_snow, sites=stream_names)
    
    ep_snow = stepwise_BIC_snow(target="log_ptot_yield", data=eagle_snow, sites=stream_names)
    jp_snow = stepwise_BIC_snow(target="log_ptot_yield", data=joosvalley_snow, sites=stream_names)
    op_snow = stepwise_BIC_snow(target="log_ptot_yield", data=otter_snow, sites=stream_names)
    bp_snow = stepwise_BIC_snow(target="log_ptot_yield", data=brewery_snow, sites=stream_names)
    gp_snow = stepwise_BIC_snow(target="log_ptot_yield", data=garfoot_snow, sites=stream_names)
    kp_snow = stepwise_BIC_snow(target="log_ptot_yield", data=kuenster_snow, sites=stream_names)
    rp_snow = stepwise_BIC_snow(target="log_ptot_yield", data=rattlesnake_snow, sites=stream_names)
    bowp_snow = stepwise_BIC_snow(target="log_ptot_yield", data=bower_snow, sites=stream_names)
@


<<label=variable_selection_snow2, include=False, echo=False>>=
    es_snow2 = stepwise_BIC_snow2(target="log_stot_yield", data=eagle_snow, sites=stream_names)
    js_snow2 = stepwise_BIC_snow2(target="log_stot_yield", data=joosvalley_snow, sites=stream_names)
    os_snow2 = stepwise_BIC_snow2(target="log_stot_yield", data=otter_snow, sites=stream_names)
    bs_snow2 = stepwise_BIC_snow2(target="log_stot_yield", data=brewery_snow, sites=stream_names)
    gs_snow2 = stepwise_BIC_snow2(target="log_stot_yield", data=garfoot_snow, sites=stream_names)
    ks_snow2 = stepwise_BIC_snow2(target="log_stot_yield", data=kuenster_snow, sites=stream_names)
    rs_snow2 = stepwise_BIC_snow2(target="log_stot_yield", data=rattlesnake_snow, sites=stream_names)
    bows_snow2 = stepwise_BIC_snow2(target="log_stot_yield", data=bower_snow, sites=stream_names)
    
    ep_snow2 = stepwise_BIC_snow2(target="log_ptot_yield", data=eagle_snow, sites=stream_names)
    jp_snow2 = stepwise_BIC_snow2(target="log_ptot_yield", data=joosvalley_snow, sites=stream_names)
    op_snow2 = stepwise_BIC_snow2(target="log_ptot_yield", data=otter_snow, sites=stream_names)
    bp_snow2 = stepwise_BIC_snow2(target="log_ptot_yield", data=brewery_snow, sites=stream_names)
    gp_snow2 = stepwise_BIC_snow2(target="log_ptot_yield", data=garfoot_snow, sites=stream_names)
    kp_snow2 = stepwise_BIC_snow2(target="log_ptot_yield", data=kuenster_snow, sites=stream_names)
    rp_snow2 = stepwise_BIC_snow2(target="log_ptot_yield", data=rattlesnake_snow, sites=stream_names)
    bowp_snow2 = stepwise_BIC_snow2(target="log_ptot_yield", data=bower_snow, sites=stream_names)
@


<<label=variable_selection_snow2_yield, include=False, echo=False>>=
    esy_snow2 = stepwise_BIC_snow2(target="log_stot_yield", data=eagle_snow, sites=stream_names)
    jsy_snow2 = stepwise_BIC_snow2(target="log_stot_yield", data=joosvalley_snow, sites=stream_names)
    osy_snow2 = stepwise_BIC_snow2(target="log_stot_yield", data=otter_snow, sites=stream_names)
    bsy_snow2 = stepwise_BIC_snow2(target="log_stot_yield", data=brewery_snow, sites=stream_names)
    gsy_snow2 = stepwise_BIC_snow2(target="log_stot_yield", data=garfoot_snow, sites=stream_names)
    ksy_snow2 = stepwise_BIC_snow2(target="log_stot_yield", data=kuenster_snow, sites=stream_names)
    rsy_snow2 = stepwise_BIC_snow2(target="log_stot_yield", data=rattlesnake_snow, sites=stream_names)
    bowsy_snow2 = stepwise_BIC_snow2(target="log_stot_yield", data=bower_snow, sites=stream_names)
    
    epy_snow2 = stepwise_BIC_snow2(target="log_ptot_yield", data=eagle_snow, sites=stream_names)
    jpy_snow2 = stepwise_BIC_snow2(target="log_ptot_yield", data=joosvalley_snow, sites=stream_names)
    opy_snow2 = stepwise_BIC_snow2(target="log_ptot_yield", data=otter_snow, sites=stream_names)
    bpy_snow2 = stepwise_BIC_snow2(target="log_ptot_yield", data=brewery_snow, sites=stream_names)
    gpy_snow2 = stepwise_BIC_snow2(target="log_ptot_yield", data=garfoot_snow, sites=stream_names)
    kpy_snow2 = stepwise_BIC_snow2(target="log_ptot_yield", data=kuenster_snow, sites=stream_names)
    rpy_snow2 = stepwise_BIC_snow2(target="log_ptot_yield", data=rattlesnake_snow, sites=stream_names)
    bowpy_snow2 = stepwise_BIC_snow2(target="log_ptot_yield", data=bower_snow, sites=stream_names)
@


<<label=breakdown_snow_or_rain, include=False, echo=False>>=
    for(target in c('ptot_tot', 'pstorm_tot', 'stot_tot', 'sstorm_tot'))
    {
        p = percentages(streams, target, col.names=c("snowmelt-driven", "rainfall-driven"))
        pp = as.matrix( proportions(streams, target, col.names=c("snowmelt-driven", "rainfall-driven")) )
        
        variable_name = paste(target, "_percentages", sep="")
        variable_name2 = paste(target, "_proportions", sep="")
        
        assign(variable_name, value=p)
        assign(variable_name2, value=pp)
    }
@


<<label=barchart, echo=False, include=False>>=
    layout(matrix(1:4,2,2))
    colors <- gray.colors(dim(ptot_tot_proportions)[1])
    
    barplot(ptot_tot_proportions, beside=T, names.arg=c("snow","rain"), ylab="proportion of phosphorus")
    barplot(stot_tot_proportions, beside=T, names.arg=c("snow","rain"), ylab="proportion of solids")
    barplot(pstorm_tot_proportions, beside=T, names.arg=c("snow","rain"), ylab="proportion of phosphorus")
    barplot(sstorm_tot_proportions, beside=T, names.arg=c("snow","rain"), ylab="proportion of solids")
    legend(x="topleft", legend=streams, fill=colors, bty='n')
@



\begin{figure}[h!]
    \begin{center}
<<label=fig2, fig=True, echo=False, width=6, height=8.5>>=
<<barchart>>
@
    \end{center}
    \vspace{-10mm}
    \caption{Cumulative storm loadings at the four creeks.\label{bars}}
\end{figure}


<<label=stot_boxplots, echo=False, include=False>>=
    yy = c(-2, 3.5)
    xx = c(1, 3*length(streams) + 1)
    par(mar=c(4, 4, 2, 0))
    plot.new()
    plot.window(xlim=xx, ylim=yy)
    
    for(i in 1:length(streams))
    {
        data = get(streams[i])
        site = stream_names[[streams[i]]]
        bplot(log_stot_yield~snow, data=eagle, loc=3*i, classes=c("snow","rain"), site=site, xlim=xx)
    }
    
    mtext("count:", side=3, line=1, cex=0.7, at=0, adj=1 )
    mtext("proportion:", side=3, line=0, cex=0.7, at=0, adj=1 )
@



<<label=ptot_boxplots, echo=False, include=False>>=
    xx = c(1, 3*length(streams) + 1)
    par(mar=c(4, 4, 2, 0))
    plot.new()
    plot.window(xlim=xx, ylim=yy)
    
    for(i in 1:length(streams))
    {
        data = get(streams[i])
        site = stream_names[[streams[i]]]
        bplot(log_ptot_yield~snow, data=eagle, loc=3*i, classes=c("snow","rain"), site=site, xlim=xx)
    }
    
    mtext("count:", side=3, line=1, cex=0.7, at=0, adj=1 )
    mtext("proportion:", side=3, line=0, cex=0.7, at=0, adj=1 )
@





%Boxplots of the contribution from individual storm events
\begin{figure}[h]
    \setkeys{Gin}{width=1\textwidth}    %make figures a bit wider than the Sweave default.
    \begin{center}
<<label=boxplot_stot, fig=True, echo=False, width=9, height=5>>=
<<stot_boxplots>>
@ \\
    \vspace{15mm}
<<label=boxplot_ptot, fig=True, echo=False, width=9, height=5>>=
<<ptot_boxplots>>
@
    \caption{Boxplots showing the sediment and phosphorus load produced by individual events at all four streams.\label{boxplots}}
    \end{center}
\end{figure}




<<label=cumulative_sloading_by_rainfall, include=False, echo=False>>=
    line_type=1
    color=1
    yy=c(0,1)
    xx = c(0,max(aggregate[aggregate$snow==FALSE,]$theisen, na.rm=T))
    
    for(stream in streams)
    {
        stream_data = get(stream)
        
        non_snow = stream_data[stream_data$snow==FALSE & !is.na(stream_data$ptot_tot),]
        non_snow_sorted = non_snow[ order(non_snow$theisen) ,]
        y = cumsum(non_snow_sorted$stot_tot)/sum(stream_data$stot_tot, na.rm=T)
        
        stream_data = get(stream)
        plot( x=non_snow_sorted$theisen, y=y, type='l', xlab="Theisen rainfall",
            ylab=paste('proportion of total sediment load'), lty=line_type, col=color, bty='n', lwd=2, ylim=yy, xlim=xx)
        par(new=T, ann=F, xaxt='n', yaxt='n')
        line_type = line_type+1
    }
    legend(x='topleft', bty='n', legend=streams, lty=1:length(streams))
@

<<label=cumulative_ploading_by_rainfall, include=False, echo=False>>=
    line_type=1
    color=1
    yy=c(0,1)
    xx = c(0,max(aggregate[aggregate$snow==FALSE,]$theisen, na.rm=T))
    
    for(stream in streams)
    {
        stream_data = get(stream)
        
        non_snow = stream_data[stream_data$snow==FALSE & !is.na(stream_data$ptot_tot) & !is.na(stream_data$theisen),]
        non_snow_sorted = non_snow[ order(non_snow$theisen) ,]
        y = cumsum(non_snow_sorted$ptot_tot)/sum(stream_data$ptot_tot, na.rm=T)
        
        stream_data = get(stream)
        plot( x=non_snow_sorted$theisen, y=y, type='l', xlab="Theisen rainfall",
            ylab=paste('proportion of total phosphorus load'), lty=line_type, col=color, bty='n', lwd=2, ylim=yy, xlim=xx)
        par(new=T, ann=F, xaxt='n', yaxt='n')
        line_type = line_type+1
    }
    legend(x='topleft', bty='n', legend=streams, lty=1:length(streams))
@


<<label=cdf_plot, include=False, echo=False>>=
    line_type=1
    color=1
    for(stream in streams)
    {
        stream_data = get(stream)
        plot( y=cumsum(sort(stream_data[,'sstorm_tot'], decreasing=T)) / sum(stream_data[,'sstorm_tot']),
              x=1:length(stream_data[,'sstorm_tot']) / length(stream_data[,'sstorm_tot']), type='l', 
              xlab='fraction of events', ylab='fraction of loading', lty=line_type, col=color, bty='n', lwd=2)
        par(new=T, ann=F, xaxt='n', yaxt='n')
        line_type = line_type+1
    }
    legend(x='bottomright', bty='n', legend=streams, lty=c(1,2,3,4))
@



<<label=proportion, include=False, echo=False>>=
    q_90 = list()
    
    for(target in c("stot_tot", "ptot_tot"))
    {
        output = paste(target, "_major", sep="")
        q=vector()
        for(stream_name in streams){
            stream = get(stream_name)
            stream[output] <- with(stream, ifelse(get(target)>quantile(get(target), 0.9, na.rm=T),1,0))
            stream$major <- with(stream, ifelse(get(target)>quantile(get(target), 0.9, na.rm=T),1,0))
            proportion = sum(stream[stream[output]==1,target], na.rm=T)/sum(stream[,target], na.rm=T)
            q = c(q, proportion)
            assign(stream_name, stream) }
            
        names(q) = streams
        q_90[[target]] = q
    }
@


<<label=kruskal, include=False, echo=False, eval=False>>=
    library(coin)
    
    targets = c("stot_tot", "ptot_tot")
    kruskal_results = list()
    
    for (stream in streams)
    {
        result = list()
        stream_data = get(stream)
        
        for (target in targets)
        {
            target_data = stream_data[!is.na(stream_data[,target]), ]
            annual = list()
            
            for (year in unique(target_data$year))
            {
                if (dim(target_data[target_data$year==year, ])[1] >= 20)
                    annual[[as.character(year)]] = target_data[target_data$year==year, target]
            }
            result[[target]] = kruskal.test(annual)
        }
        kruskal_results[[stream]] = result
    }
@
    
    
<<label=by_year, include=False, echo=False, eval=False>>=
    for (year in unique(bower$water_year))
    {
        annual = bower[bower$water_year==year,]
        major_s <- with(annual, ifelse(get("stot_tot")>quantile(get("stot_tot"), 0.9, na.rm=T),1,0))
        major_p <- with(annual, ifelse(get("ptot_tot")>quantile(get("ptot_tot"), 0.9, na.rm=T),1,0))
        cat( paste(year, "\n") )
        cat( paste("number of events: ", dim(annual)[1], "\n", sep="") )
        cat( paste("sediment: total: ", sum(annual$stot_tot), ", rain: ", sum(annual$stot_tot[annual$snow==FALSE]),
                   ", snow: ", sum(annual$stot_tot[annual$snow==TRUE]), "\n") )
        cat( paste("proportion of sediment carried by year's biggest events: ", 
                   round(sum(annual$stot_tot[major_s==1], na.rm=T)/sum(annual$stot_tot, na.rm=T), 3), "\n") )
        cat( paste("proportion of sediment carried by year's biggest event: ", 
                   round(max(annual$stot_tot, na.rm=T)/sum(annual$stot_tot, na.rm=T), 3), "\n") )
        cat( paste("date of biggest sediment event: ",  annual$start_day[which.max(annual$stot_tot)], "\n") )
        cat( paste("phosphorus: total: ", sum(annual$ptot_tot), ", rain: ", sum(annual$ptot_tot[annual$snow==FALSE]), 
                   ", snow: ", sum(annual$ptot_tot[annual$snow==TRUE]), "\n") )
        cat( paste("proportion of phosphorus carried by year's biggest events: ", 
                   round(sum(annual$ptot_tot[major_p==1], na.rm=T)/sum(annual$ptot_tot, na.rm=T), 3), "\n") )
        cat( paste("proportion of phosphorus carried by year's biggest event: ", 
                   round(max(annual$ptot_tot, na.rm=T)/sum(annual$ptot_tot, na.rm=T), 3), "\n") )
        cat( paste("date of biggest phosphorus event: ",  annual$start_day[which.max(annual$ptot_tot)], "\n") )
    }
@



\section{Goal}
Stream health is threatened by high sediment and phosphorus loads, which are carried into the streams by runoff from the surrounding landscape. It has been shown previously\cite{Danz:2010} that the phosphorus and sediment loads in Wisconsin are not evenly distributed in time - rather, most of the annual loading arrives during two pulses: one in early spring, associated with the melting of the winter snowpack, and the other in midsummer, at the same time as the most intense summer thunderstorms. In this study, we define loading "events" that can span multiple days of continuous runoff. Our goal is to then characterize the events that produce the greatest loading, in order to inform management practices that aim to improve stream health by reducing sediment and phosphorus loads.\\

\section{Data}
\paragraph{Description}
The data in this report comes from eight Wisconsin streams that were monitored (with some gaps in data collection) between 1989 and 2009. The streams and the period during which each was monitored are:

\begin{table}[h]
\begin{center}
\begin{tabular}{r c l}
        \textbf{Stream}  & \textbf{Events} & \textbf{Years}\\
        Eagle & 429 & 1991-1994, 2003-2007\\
        Joos Valley & 473 & 1990-1994, 2002-2007\\
        Otter & 424 & 1990-1997, 2000-2002\\
        Brewery & 670 & 1985, 1990-1998, 2000-2001\\
        Garfoot & 527 & 1985, 1990-1993, 1995-1998\\
        Kuenster & 218 & 1992-1995\\
        Rattlesnake & 170 & 1991-1994\\
        Bower & 373 & 1990-1994, 2006-2009\\
    \end{tabular}
\end{center}
\end{table}

Each entry in our data set represents one loading event, which is defined based on the hydrograph - the event begins when the loading rises from a base level toward a peak, and ends when the loading falls back to its new base level. Two kinds of load are measured for each event - the sediment load and the phosphorus load. There are two typical ways that sediment and phosphorus get into streams: they can be carried by runoff during a rainstorm or by melting snow. The load from each event can be divided into two components: the base flow component and the storm flow component. The two components refer, respectively, to the load carried by the stream's underlying base flow and to that carried by the additional stormwater pulse.\\

The phosphorus loading was not measured at Brewery Creek from October 1999 onward.\\

Not all of the data can be collected for each event. For instance, rainfall is measured only when the ground is free of snow, because snow interferes with the rain gauges. And the amount of snowmelt is estimated by multiplying the snow's water content by the change in snow depth during a warm snap, which is inaccurate when additional snow falls during the event. Broadly, there is one set of measurements that are made during rainfall-driven events and a different set of measurements that are made during snowmelt-driven events. Because of this, the two types of event are modeled separately.\\

\paragraph{Exploratory Analysis}
The first task was to determine how loads are distributed between snowmelt-driven and rainfall-driven events. The total loads from each kind of event are tabulated in Tables \ref{tab:stot} (sediment) and \ref{tab:ptot} (phosphorus). Figure \ref{bars} presents the same information as the tables, while Figure \ref{boxplots} also compares the load from indivudual snowmelt- and rainfall-driven events. In general, more of the load of both phosphorus and sediment is from rainfall-driven events, but at Garfoot and Kuenster more of the both kinds of load came from snowmelt-driven events. At all sites except Garfoot and Kuenster, snowmelt-driven events contributed a larger proportion of phosphorus loading than of sediment loading (and at Garfoot and Kuenster, difference between the proportions was small.) At most sites the difference between the proportion of sediment load produced by snowmelt-driven events and the proportion of phosphorus load produced by snowmelt-driven events was less than ten percentage points, but at Bower the difference was about 34 percentage points. This suggests that melting snow carries proportionally more phosphorus than does rainfall-runoff, which might be the case if the the phosphorus is from animal poop that accumulates on fallen snow, while the sediment comes from dirt that is mainly trapped under the snowpack.\\

Note: initial analysis suggests that the major events are not evenly distributed, but occur more often in some years than in others. It may also be the case that the major phosphorus-loading events and the major sediment-loading events occur in different years, and that the years with more major snowmelt-driven events are not the same years as those with more rainfall-driven events. We need to test the hypotheses that there is no significant difference between years in the proportion of events that become major events. This could be done by a rank-sum test, where phosphorus- (or sediment-)loading events are ranked and then the sum of the ranks for 2007, say, is compared to what we should see under a uniform hypothesis... How to test whether the major sediment and phosphorus events occur in the same years, and whether the major snowmelt-driven and rainfall-driven events happen in the same years? I do not yet know.

We investigated dividing the snow-free seasons into early and late subseasons, separating the two on May 15th of each year. If vegetation serves to hold the soil together, and to increase both evapotranspiration and infiltration, then erosion may be more common early in the spring before most of the summer's vegetation appears. If so, the relationship between rainfall and the stream's loading might change during the summer.\\

The investigation was done by making linear models to describe the sediment and phosphorus loading during the two subseasons and comparing them to a single model fit to the entire snow-free period. Because the split makes the model more flexible, it will certainly improve the model's fit - the question is whether that improvement is enough to justify making the model more complex. At all four streams, the model improvement was statistically significant but too small to matter (the split models explained about 1\%-2\% more of the loads). We will not use the split in the rest of the analysis.\\

<<label=total_solids_table,echo=FALSE,results=tex>>=
    library(xtable)
    print(xtable(stot_tot_percentages, caption="Proportion of total suspended solids loading contributed by each type of event",
                 label="tab:stot", align=c('l', 'c', 'c')),
    caption.placement="bottom", hline.after=0 )
@

<<label=total_phosphorus_table,echo=FALSE,results=tex>>=
    library(xtable)
    print(xtable(ptot_tot_percentages, caption="Proportion of total phosphorus loading contributed by each type of event",
                 label="tab:ptot", align=c('l', 'c', 'c')), 
          caption.placement="bottom", hline.after=0 )
@

Over the course of the monitoring period, the majority of the total load (both of sediment and of phosphorus) was carried during just a few major events. Just 10\% of the events carried between \Sexpr{round( 100*min(q_90$stot_tot), 1 )}\% (at \Sexpr{stream_names[[names(which.min(q_90$stot_tot))]]}) and \Sexpr{round( 100*max(q_90$stot_tot), 1 )}\% (at \Sexpr{stream_names[[names(which.max(q_90$stot_tot))]]}) of the total sediment load; the same events produced between \Sexpr{round( 100*min(q_90$ptot_tot), 1 )}\% (at \Sexpr{stream_names[[names(which.min(q_90$ptot_tot))]]}) and \Sexpr{round( 100*max(q_90$ptot_tot), 1 )}\% (at \Sexpr{stream_names[[names(which.max(q_90$ptot_tot))]]}) of the total phosphorus load.\\


<<label=breakdown_major_events_rain_or_snow, echo=False>>=
    prp_major = proportions(streams, "stot_tot_major", col.names=c("snowmelt-driven", "rainfall-driven"))
    prp_all = proportions(streams, "event", col.names=c("snowmelt-driven", "rainfall-driven"))
@


\begin{table}[h] \small
    \begin{center}
    \begin{tabular}{lrl}
    \textbf{Sediment} & $R^2$ & Model terms \\
    \hline
<<sediment_selection_table, echo=False, include=True, results=tex>>=
R2_table(es)
R2_table(js)
R2_table(os)
R2_table(bs)
R2_table(gs)
R2_table(ks)
R2_table(rs)
R2_table(bows)
@
    \end{tabular}
    \caption{\label{sed_r_square_nosnow}}
    \end{center}
\end{table}

\begin{table}[h] \small
    \begin{center}
    \begin{tabular}{lrl}
    \textbf{Phosphorus} & $R^2$ & Model terms \\
    \hline
<<phosphorus_selection_table, echo=False, include=True, results=tex>>=
R2_table(ep)
R2_table(jp)
R2_table(op)
R2_table(bp)
R2_table(gp)
R2_table(kp)
R2_table(rp)
R2_table(bowp)
@
    \end{tabular}
    \caption{\label{phos_r_square_nosnow}}
    \end{center}
\end{table}


\begin{table}[h] \small
    \begin{center}
    \begin{tabular}{lrl}
    \textbf{Sediment} & $R^2$ & Model terms \\
    \hline
<<sediment_selection_table, echo=False, include=True, results=tex>>=
R2_table(es_snow2)
R2_table(js_snow2)
R2_table(os_snow2)
R2_table(bs_snow2)
R2_table(gs_snow2)
R2_table(ks_snow2)
R2_table(rs_snow2)
R2_table(bows_snow2) 
@
    \end{tabular}
    \caption{\label{sed_r_square_nosnow}}
    \end{center}
\end{table}



\begin{table}[h] \small
    \begin{center}
    \begin{tabular}{lrl}
    \textbf{Phosphorus} & $R^2$ & Model terms \\
    \hline
<<phosphorus_selection_table, echo=False, include=True, results=tex>>=
R2_table(ep_snow2)
R2_table(jp_snow2)
R2_table(op_snow2)
R2_table(bp_snow2)
R2_table(gp_snow2)
R2_table(kp_snow2)
R2_table(rp_snow2)
R2_table(bowp_snow2)
@
    \end{tabular}
    \caption{\label{phos_r_square_nosnow}}
    \end{center}
\end{table}


\section{Analysis}

\subsection{Variable selection}
In order to make a model of the load carried by the stream, we need to select the predictor variables that have explanatory power. We used stepwise regression with the Bayesian Information Criterion (BIC) to screen the potential predictor variables.

\paragraph{Rainfall-driven events} The predictors that survived the screening at each stream are listed in Table \ref{nosnow_predictor_list}. The variables are listed in the order of their importance to the model.\\

\begin{table}[h!]\small
    \begin{center}
    \begin{tabular}{ll}
        \textbf{Solids} & \\
        \hspace{5mm} Eagle: & \Sexpr{ sanipaste2(es$ranked, collapse=", ") }\\
        \hspace{5mm} Joos: & \Sexpr{ sanipaste2(js$ranked, collapse=", ") }\\
        \hspace{5mm} Otter: & \Sexpr{ sanipaste2(os$ranked, collapse=", ") }\\
        \hspace{5mm} Brewery: & \Sexpr{ sanipaste2(bs$ranked, collapse=", ") }\\
        \hspace{5mm} Garfoot: & \Sexpr{ sanipaste2(gs$ranked, collapse=", ") }\\
        \hspace{5mm} Kuenster: & \Sexpr{ sanipaste2(ks$ranked, collapse=", ") }\\
        \hspace{5mm} Rattlesnake: & \Sexpr{ sanipaste2(rs$ranked, collapse=", ") } \\
        \hspace{5mm} Bower: & \Sexpr{ sanipaste2(bows$ranked, collapse=", ") }
    \vspace{2mm}\\
        \textbf{Phosphorus} & \\
        \hspace{5mm} Eagle: & \Sexpr{ sanipaste2(ep$ranked, collapse=", ") }\\
        \hspace{5mm} Joos: & \Sexpr{ sanipaste2(jp$ranked, collapse=", ") }\\
        \hspace{5mm} Otter: & \Sexpr{ sanipaste2(op$ranked, collapse=", ") }\\
        \hspace{5mm} Brewery: & \Sexpr{ sanipaste2(bp$ranked, collapse=", ") }\\
        \hspace{5mm} Garfoot: & \Sexpr{ sanipaste2(gp$ranked, collapse=", ") }\\
        \hspace{5mm} Kuenster: & \Sexpr{ sanipaste2(kp$ranked, collapse=", ") }\\
        \hspace{5mm} Rattlenake: & \Sexpr{ sanipaste2(rp$ranked, collapse=", ") }\\
        \hspace{5mm} Bower: & \Sexpr{ sanipaste2(bowp$ranked, collapse=", ") }\\
    \end{tabular}
    \caption{The most important variables in the models for rainfall-driven loading. The variables are ordered by their importance to the model of the load. \label{nosnow_predictor_list}}
    \end{center}
\end{table}

In every case, the theisen rainfall is the most important predictor, followed usually by antecedent baseflow. Using just those two predictors results in an $R^2$ greater than 0.7 in most models (the exception is at Brewery Creek - see Tables \ref{sed_r_square_nosnow} and \ref{phos_r_square_nosnow}.) Since the antecedent baseflow is considered an indicator of how wet is in the watershed before each event, we conclude that the amount of sediment and phosphorus washed into a stream by each event is mainly a function of the quantity of water in the system. At Brewery Creek, the intensity of rainfall is a more important predictor than the total quantity of rain.\\

\paragraph{Snowmelt-driven events} We had less success modeling the loading produced by the snowmelt-driven events. The predictors that survived the screening process were different from stream to stream and those variables that did survive at most sites weren't always selected in the same order (like they were for the rainfall-driven events). What's more, the models for snowmelt-driven events were less accurate than for rainfall-driven events, ranging in $R^2$ from 0.24 to 0.53, with most in the 0.45 range.\\

At most sites, the most important predictor was a temperature measurement, either the maximum or the mean temperature during the loading event. The antecedent baseflow also appears to be important at most sites. It seems likely that, as in the case of rainfall-driven events, the loading is driven by the quantity of water that moves through the watershed during the event.

\begin{table}[h!]\small
    \begin{center}
    \begin{tabular}{ll}
        \textbf{Solids} & \\
        \hspace{5mm} Eagle: & \Sexpr{ sanipaste2(es_snow$ranked, collapse=", ") }\\
        \hspace{5mm} Joos: & \Sexpr{ sanipaste2(js_snow$ranked, collapse=", ") }\\
        \hspace{5mm} Otter: & \Sexpr{ sanipaste2(os_snow$ranked, collapse=", ") }\\
        \hspace{5mm} Brewery: & \Sexpr{ sanipaste2(bs_snow$ranked, collapse=", ") }\\
        \hspace{5mm} Garfoot: & \Sexpr{ sanipaste2(gs_snow$ranked, collapse=", ") }\\
        \hspace{5mm} Kuenster: & \Sexpr{ sanipaste2(ks_snow$ranked, collapse=", ") }\\
        \hspace{5mm} Rattlesnake: & \Sexpr{ sanipaste2(rs_snow$ranked, collapse=", ") } \\
        \hspace{5mm} Bower: & \Sexpr{ sanipaste2(bows_snow$ranked, collapse=", ") }
    \vspace{2mm}\\
        \textbf{Phosphorus} & \\
        \hspace{5mm} Eagle: & \Sexpr{ sanipaste2(ep_snow$ranked, collapse=", ") }\\
        \hspace{5mm} Joos: & \Sexpr{ sanipaste2(jp_snow$ranked, collapse=", ") }\\
        \hspace{5mm} Otter: & \Sexpr{ sanipaste2(op_snow$ranked, collapse=", ") }\\
        \hspace{5mm} Brewery: & \Sexpr{ sanipaste2(bp_snow$ranked, collapse=", ") }\\
        \hspace{5mm} Garfoot: & \Sexpr{ sanipaste2(gp_snow$ranked, collapse=", ") }\\
        \hspace{5mm} Kuenster: & \Sexpr{ sanipaste2(kp_snow$ranked, collapse=", ") }\\
        \hspace{5mm} Rattlesnake: & \Sexpr{ sanipaste2(rp_snow$ranked, collapse=", ") }\\
        \hspace{5mm} Bower: & \Sexpr{ sanipaste2(bowp_snow$ranked, collapse=", ") }\\
    \end{tabular}
    \caption{The most important variables in the models for snowmelt-driven loading. The variables are ordered by their importance to the model of the load. \label{snow_predictor_list}}
    \end{center}
\end{table}

\section{Conclusions}
We have learned that we can predict the loading that will result from a storm with good accuracy, based just on the base flow before the storm and on the amount of rain that falls during the storm. Antecedent base flow is a measurement of how much water is in the watershed before a storm and any new water comes as rainfall, so it seems that the sediment and phosphorus loads are driven mainly by the quantity of water moving through the watershed. We have not yet found an accurate way to model the amount of load during a snowmelt-driven event but we have seen that the air temperature (which drives snowmelt), the antecedent base flow, and the amount of additional precipitation are important predictors for those events.\\

Most of the annual loading seems to be produced by a few major events. Characterizing these events will be an important step in describing the distribution of loadings and in informing management practices.\\

\section{Next steps}
There are at least two more creeks to include in the analysis. We also need to decide if there is an effective way to predict whether any given event will be one of the major events that produce most of the loading. Figures \ref{cdf-s} and \ref{cdf-p} make it look like the majority of the ranfall-driven loading comes from storms that drop at least two inches of rain. Mitigating the effect of large storms will probably require slowing the water's movement through the watershed - for instance, by impounding runoff before it can flow into the creeks. Our analysis will look at the frequency of big storms in order to get an idea of how quickly impounded water must be dealt with in order to be ready for the next event.


\begin{figure}
    \begin{center}
<<label=figure2, fig=True, echo=False, width=6, height=5>>=
<<cumulative_sloading_by_rainfall>>
@
    \end{center}
    \caption{Proportion of the total sediment load contributed by rainfall events up to the size shown. Snowmelt-driven events are excluded.\label{cdf-p}}
\end{figure}

\begin{figure}
    \begin{center}
<<label=figure3, fig=True, echo=False, width=6, height=5>>=
<<cumulative_ploading_by_rainfall>>
@
    \end{center}
    \caption{Proportion of the total phosphorus load contributed by rainfall events up to the size shown. Snowmelt-driven events are excluded.\label{cdf-s}}
\end{figure}

\begin{figure}
    \begin{center}
<<label=figure4, fig=True, echo=False, width=12, height=15>>=
<<bubble_plots>>
@
    \end{center}
    \caption{Antecedent base flow is the horizontal axis; theisen rainfall is the vertical axis. Each dot represents one event. The size of the dot shows the total sediment load contributed by that event. \label{bubbles}}
\end{figure}

<<label=guide, echo=False, results=tex, include=False, eval=False>>=
    stream = "eagle"
    stream = get(stream)
    
    snow = stream[stream$snow==TRUE,]
    guide(stot_tot~nws_prec + total_water + nws_snow + melt_snow + tmean + tmax + tmin + sweq + julian + sin_julian + cos_julian,
          data=snow, sweave=T, cv_gain=0)
    
    rain = stream[stream$snow==FALSE,]
    guide(stot_tot~nws_prec+event_type+ap_1day+ap_2day+ap_3day+total_water+theisen+sweq+julian+sin_julian+cos_julian+tmean+tmax+tmin,
          data=rain, sweave=T, cv_gain=0)
@

\bibliographystyle{plain}
\bibliography{../references/loadings}

\end{document}
